{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "This  material,  no  matter  whether  in  printed  or  electronic  form,  \n",
    "may  be  used  for  personal  and non-commercial educational use only.  \n",
    "Any reproduction of this manuscript, no matter whether as a whole or in parts, \n",
    "no matter whether in printed or in electronic form, \n",
    "requires explicit prior acceptance of the authors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Assignment 3 - WS 2023 -->\n",
    "\n",
    "# Convolutional Neural Networks (22 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the third assignment for the exercises in Deep Learning and Neural Nets 1.\n",
    "It provides a skeleton, i.e. code with gaps, that will be filled out by you in different exercises.\n",
    "All exercise descriptions are visually annotated by a vertical bar on the left and some extra indentation,\n",
    "unless you already messed with your jupyter notebook configuration.\n",
    "Any questions that are not part of the exercise statement do not need to be answered,\n",
    "but should rather be interpreted as triggers to guide your thought process.\n",
    "\n",
    "**Note**: The cells in the introductory part (before the first subtitle)\n",
    "perform all necessary imports and provide utility function that should work without problems.\n",
    "Please, do not alter this code or add extra import statements in your submission, unless it is explicitly requested!\n",
    "\n",
    "<span style=\"color:#d95c4c\">**IMPORTANT:**</span> Please, change the name of your submission file so that it contains your student ID!\n",
    "\n",
    "In this assignment, the goal is to get familiar with **Convolutional Neural Networks**. Essentially, a CNN is a multi-layer perceptron that uses convolutional instead of fully connected layers. Since convolutions are known to be useful for image processing, CNNs have become a powerful tool for learning features from images. However, they have proven to beat alternative architectures in a variety of other domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from nnumpy import Module\n",
    "from nnumpy.utils import sig2col\n",
    "from nnumpy.testing import gradient_check\n",
    "\n",
    "rng = np.random.default_rng(1856)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution\n",
    "\n",
    "The main difference of CNNs with the fully connected networks we tackled thus far, is the *convolution operation*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The Math\n",
    "\n",
    "Mathematically, a (discrete) convolution operates on two functions, so that\n",
    "\n",
    "$$(f * g)[n] = \\sum_{k \\in \\mathbb{Z}} f[k] g[n - k].$$\n",
    "\n",
    "For image processing, the discrete functions $f$ and $g$ and replaced by images. After all, an image can be considered a function of pixel indices to pixel intensities. Also, images have (at least) two dimensions: width and height. Therefore, if we represent images as matrices of pixel intensities, we can write the convolution of an image $\\boldsymbol{X} \\in \\mathbb{R}^{H \\times W}$ with a so-called *kernel* $\\boldsymbol{K} \\in \\mathbb{R}^{R_1 \\times R_2}$ as follows:\n",
    "\n",
    "$$(\\boldsymbol{K} * \\boldsymbol{X})_{a,b} = \\sum_{i=1}^{R_1} \\sum_{j=1}^{R_2} k_{i,j} x_{a - i + 1,b - j + 1}.$$\n",
    "\n",
    "Instead of using the actual convolution operation, convolutional layers are often implemented as the *cross-correlation* of kernel and image instead:\n",
    "\n",
    "$$(\\boldsymbol{K} \\star \\boldsymbol{X})_{a,b} = \\sum_{i=1}^{R_1} \\sum_{j=1}^{R_2} k_{i,j} x_{a + i - 1,b + j - 1}.$$\n",
    "\n",
    "It might be useful to note that unlike the convolution, the cross-correlation is not commutative, i.e. $\\boldsymbol{K} \\star \\boldsymbol{X} \\neq \\boldsymbol{X} \\star \\boldsymbol{K}$, whereas $\\boldsymbol{K} * \\boldsymbol{X} = \\boldsymbol{X} * \\boldsymbol{K}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Cross-correlation vs Convolution (3 Points)\n",
    "\n",
    "Implementation-wise, there is little difference between cross-correlation and convolution. It is even quite straightforward to implement one, given an implementation of the other. To keep things simple, this exercise is limited to the one-dimensional variants of these operations (for now). How hard would it be to make your implementation of the convolution function commutative?\n",
    "\n",
    "> Implement functions to compute the cross-correlations and convolutions of one-dimensional signals. Obviously, you should **not** use functions like `np.convolve` or `np.correlate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e449e453030b5edd8cee54b27ee6ce97",
     "grade": false,
     "grade_id": "cell-8c80de2faae7eb03",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cross_correlation1d(x, k):\n",
    "    \"\"\"\n",
    "    Compute a one-dimensional cross-correlation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : (L, ) ndarray\n",
    "        Input data for the cross-correlation.\n",
    "    k : (R, ) ndarray\n",
    "        Kernel weights for the cross-correlation.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    features : (L') ndarray\n",
    "        Cross-correlation of the input data with the kernel.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    L = x.shape[0]\n",
    "    R = k.shape[0]\n",
    "\n",
    "    L_prime = L - R + 1\n",
    "\n",
    "    features = np.zeros(L_prime)\n",
    "\n",
    "    for i in range(L_prime): # forall a in L_prime\n",
    "        for j in range(R):\n",
    "            features[i] += x[i + j] * k[j]\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "def convolution1d(x, k):\n",
    "    \"\"\"\n",
    "    Compute a one-dimensional convolution.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : (L, ) ndarray\n",
    "        Input data for the convolution.\n",
    "    k : (R, ) ndarray\n",
    "        Kernel weights for the convolution.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    features : (L', ) ndarray\n",
    "        Result of convolving the input data with the kernel.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    L = x.shape[0]\n",
    "    R = k.shape[0]\n",
    "\n",
    "    L_prime = L - R + 1\n",
    "\n",
    "    features = np.zeros(L_prime)\n",
    "\n",
    "    for i in range(L_prime): # equivalent to the \"forall a in L_prime\"\n",
    "        for j in range(R):\n",
    "            features[i] += x[i - j] * k[j]\n",
    "    \n",
    "    return features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "11bf4e8d442e2a138c7f9a1587adcec5",
     "grade": true,
     "grade_id": "cell-f4135c5eb6975af0",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!\n",
    "x = rng.standard_normal(11)\n",
    "k = rng.standard_normal(3)\n",
    "corr = cross_correlation1d(x, k)\n",
    "assert isinstance(corr, np.ndarray), (\n",
    "    \"ex1: output of cross_correlation1d is not a numpy array\"\n",
    ")\n",
    "assert corr.size == 9, (\n",
    "    \"ex1: output of cross_correlation1d has incorrect size\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e38e53c308f63c5af7dba231d9913d92",
     "grade": true,
     "grade_id": "cell-28acdeabbbbe0935",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "61d4682efc99c8ee8d7f99423f9bf7d1",
     "grade": true,
     "grade_id": "cell-b2e2976b6cbc57a3",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!\n",
    "x = rng.standard_normal(11)\n",
    "k = rng.standard_normal(3)\n",
    "conv = convolution1d(x, k)\n",
    "assert isinstance(conv, np.ndarray), (\n",
    "    \"ex1: output of convolution1d is not a numpy array\"\n",
    ")\n",
    "assert conv.size == 9, (\n",
    "    \"ex1: output of convolution1d has incorrect size\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bbd985ea9699751e381b898c127d7474",
     "grade": true,
     "grade_id": "cell-f81d01bb5e648faa",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The Code\n",
    "\n",
    "This direct implementation does not offer a lot of features. For starters, it does not provide functionality to process multiple samples at once. Furthermore, practical implementations of convolutional layers normally require support for *channels*. After all, it is common practice to create multiple feature maps from a single signal to compensate for the spatial reduction through pooling and strides. These features can be incorporated in the mathematical formulation as follows:\n",
    "$$(\\boldsymbol{K} \\star \\boldsymbol{X})_{n,c_\\mathrm{out},a,b} = \\sum_{c_\\mathrm{in}=1}^{C_\\mathrm{in}} \\sum_{i=1}^{R_1} \\sum_{j=1}^{R_2} k_{c_\\mathrm{out},c_\\mathrm{in},i,j} x_{n,c_\\mathrm{in},a + i - 1,b + j - 1}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course this makes things a bit more complicated. It also introduces an extra loop over the number of input channels. In order to implement the above formula efficiently, we can use a trick that is commonly referred to as `im2col`. The idea of `im2col` is to represent the input tensor ($\\in \\mathbb{R}^{N \\times C_\\mathrm{in} \\times A \\times B}$) by a tensor in $\\mathbb{R}^{N \\times A' \\times B' \\times (C_\\mathrm{in} \\cdot R_1 \\cdot R_2)}$ where each \"column\" holds the elements in the window of the convolution. This allows the convolution to be computed as a simple matrix product with the (reshaped) kernel matrix $\\boldsymbol{K} \\in \\mathbb{R}^{C_\\mathrm{out} \\times (C_\\mathrm{in} \\cdot R_1 \\cdot R_2)}$, i.e.\n",
    "\n",
    "$$(\\boldsymbol{K} \\star \\boldsymbol{X})_{n,c_\\mathrm{out},a,b} = \\sum_{r=1}^{C_\\mathrm{in} \\cdot R_1 \\cdot R_2} x_{n,a,b,r} k_{r,c_\\mathrm{out}}.$$\n",
    "\n",
    "This trick is (efficiently) implemented in the `sig2col` function (slightly different name, since the function allows for modalities other than images). It takes **two inputs**: the signal to be convolved and the shape of the kernel as a tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [1, 2, 3],\n",
       "       [2, 3, 4],\n",
       "       [3, 4, 5],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sig2col on 1D signal\n",
    "x = np.arange(7)\n",
    "kernel_shape = (3, )\n",
    "sig2col(x, kernel_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [12, 13, 14, 15]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# image\n",
    "im = np.arange(16).reshape(4, 4)\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  4,  5,  8,  9],\n",
       "       [ 1,  2,  5,  6,  9, 10],\n",
       "       [ 2,  3,  6,  7, 10, 11],\n",
       "       [ 4,  5,  8,  9, 12, 13],\n",
       "       [ 5,  6,  9, 10, 13, 14],\n",
       "       [ 6,  7, 10, 11, 14, 15]])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3x2 windows in image as vectors\n",
    "kernel_shape = (3, 2)\n",
    "sig2col(im, (kernel_shape)).reshape(-1, 3 * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Multi-channel Convolutions (4 Points)\n",
    "\n",
    "Time to implement an actually practical convolution function that can handle multiple channels. Let us make it a 2D convolution at once.\n",
    "\n",
    " > Implement the `multi_channel_convolution2d` function below. You can use the `sig2col` function to implement the convolution by means of a dot product.\n",
    " \n",
    "**Hint:** When using the `sig2col` function, you might need to fiddle with the order of dimensions of your numpy arrays to align everything properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "40f38c090e4d8b930dfc70e3a58db385",
     "grade": false,
     "grade_id": "cell-4c0f10089977d303",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def multi_channel_convolution2d(x, k):\n",
    "    \"\"\"\n",
    "    Compute the multi-channel convolution of multiple samples.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : (N, Ci, A, B)\n",
    "    k : (Co, Ci, R1, R2)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    y : (N, Co, A', B')\n",
    "    \n",
    "    See Also\n",
    "    --------\n",
    "    sig2col : can be used to convert (N, Ci, A, B) ndarray \n",
    "              to (N, Ci, A', B', R1, R2) ndarray.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    N, _, _, _ = x.shape\n",
    "    Co, _, R1, R2 = k.shape\n",
    "\n",
    "    transformed = sig2col(x, (R1, R2)) # shape is N, Ci, A', B', R1, R2\n",
    "    transformed = transformed.transpose(0, 2, 3, 1, 4, 5) # shape is N, A', B', Ci, R1, R2\n",
    "\n",
    "    # now we multiply Ci, R1, R2 together\n",
    "    A_prime = transformed.shape[1]\n",
    "    B_prime = transformed.shape[2]\n",
    "\n",
    "    transformed = transformed.reshape(N, A_prime, B_prime, -1) # shape is now N, A', B', Ci * R1 * R2\n",
    "\n",
    "    k = k.reshape(-1, Co) # shape is Ci * R1 * R2, Co\n",
    "\n",
    "    out = transformed @ k # shape is now N, A', B', Co\n",
    "    out = out.transpose(0, 3, 1, 2) # shape is now N, Co, A', B'\n",
    "\n",
    "    return out  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3d6b77262b9cea3b6d2e1e17cfdb8cf5",
     "grade": true,
     "grade_id": "cell-c37b073450a2f668",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!\n",
    "x = rng.standard_normal(size=(10, 1, 28, 28))\n",
    "k = rng.standard_normal(size=(5, 1, 3, 3))\n",
    "s = multi_channel_convolution2d(x, k)\n",
    "assert isinstance(s, np.ndarray), (\n",
    "    \"ex2: output of multi_channel_convolution2d is not a numpy array\"\n",
    ")\n",
    "assert s.shape == (x.shape[0], k.shape[0], 26, 26), (\n",
    "    \"ex2: output of multi_channel_convolution2d has incorrect shape\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb2451009302e80a5286d43edf7fff98",
     "grade": true,
     "grade_id": "cell-8353455fb047cb09",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The Module\n",
    "\n",
    "The multi-channel convolution pretty much covers the forward pass for a typical convolutional layer. For the backward pass, we will need the gradients of this operations. In the case of the simple convolution from the first exercise, it can easily be derived that the gradients w.r.t. inputs and weights are again convolutions, since\n",
    "\n",
    "$$\\begin{aligned}\n",
    "    \\frac{\\partial L}{\\partial w_i} & = \\sum_a \\frac{\\partial L}{\\partial s_a} \\frac{\\partial s_a}{\\partial w_i} = \\sum_a \\delta_a x_{i+a} \\\\\n",
    "    \\frac{\\partial L}{\\partial x_i} & = \\sum_a \\frac{\\partial L}{\\partial s_a} \\frac{\\partial s_a}{\\partial x_i} = \\sum_{a'} w_{a'} \\delta_{i-a'},\n",
    "\\end{aligned}$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\\begin{aligned}\n",
    "    \\frac{\\partial s_a}{\\partial w_i} & = \\frac{\\partial}{\\partial w_i} \\left( \\sum_r w_r x_{a+r} \\right) = x_{a+i} \\\\\n",
    "    \\frac{\\partial s_a}{\\partial x_i} & = \\frac{\\partial}{\\partial x_i} \\left( \\sum_r w_r x_{a+r} \\right) = w_{i - a}.\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, this approach generalises to multi-channel convolutions. For the convolution of a 1D signal with $c_\\mathrm{i}$ channels so that the output has $c_\\mathrm{o}$ channels, it can be verified that\n",
    "\n",
    "$$\\begin{aligned}\n",
    "    \\frac{\\partial L}{\\partial w_{c_\\mathrm{o}, c_\\mathrm{i}, i}} & = \\sum_a \\frac{\\partial L}{\\partial s_{c_\\mathrm{o},a}} \\frac{\\partial s_{c_\\mathrm{o},a}}{\\partial w_{c_\\mathrm{o}, c_\\mathrm{i}, i}} = \\sum_a \\delta_{c_\\mathrm{o},a} x_{c_\\mathrm{i},i+a} \\\\\n",
    "    \\frac{\\partial L}{\\partial x_{c_\\mathrm{i}, i}} & = \\sum_{c_\\mathrm{o}} \\sum_a \\frac{\\partial L}{\\partial s_{c_\\mathrm{o},a}} \\frac{\\partial s_{c_\\mathrm{o},a}}{\\partial x_{c_\\mathrm{i}, i}} = \\sum_{c_\\mathrm{o}} \\sum_{a'} w_{c_\\mathrm{o}, c_\\mathrm{i}, a'} \\delta_{c_\\mathrm{o}, i-a'},\n",
    "\\end{aligned}$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\\begin{aligned}\n",
    "    \\frac{\\partial s_{c_\\mathrm{o},a}}{\\partial w_{c_\\mathrm{o}, c, i}} & = \\frac{\\partial}{\\partial w_{c_\\mathrm{o}, c, i}} \\left( \\sum_{c_\\mathrm{i}} \\sum_r w_{c_\\mathrm{o}, c_\\mathrm{i}, r} x_{c_\\mathrm{i},a+r} \\right) = x_{c, a+i} \\\\\n",
    "    \\frac{\\partial s_{c_1,a}}{\\partial x_{c_2, i}} & = \\frac{\\partial}{\\partial x_{c_2,i}} \\left( \\sum_{c_\\mathrm{i}} \\sum_r w_{c_\\mathrm{o}, c_\\mathrm{i}, r} x_{c_\\mathrm{i}, a+r} \\right) = w_{c_1, c_2, i - a}.\n",
    "\\end{aligned}$$\n",
    "\n",
    "We can conclude that the gradients of multi-channel convolutions can again be expressed as multi-channel convolutions - taking into account that we compute the convolutions for multiple samples at once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Convolutional Layer (7 Points)\n",
    "\n",
    "Now, you should be able to implement both forward and backward pass in a module. Have you already thought about the shape of the bias parameter?\n",
    "\n",
    " > Implement the `Conv2D` module below. You can use the `multi_channel_convolution2d` function from the previous exercise to implement forward and backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2411d4f8c2c7108c501b4e4fb0736080",
     "grade": false,
     "grade_id": "cell-18a7267c6de9b981",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Conv2d(Module):\n",
    "    \"\"\" Numpy DL implementation of a 2D convolutional layer. \"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, kernel_size, use_bias=True):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.use_bias = use_bias\n",
    "        \n",
    "        # create parameters 'w' and 'b'\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        if self.use_bias:\n",
    "            bias_shape = (1, out_channels, 1, 1)\n",
    "            self.register_parameter('b', np.empty(bias_shape)) # empty as we call reset_parameters later\n",
    "        self.register_parameter('w', np.empty((out_channels, in_channels, *kernel_size)))\n",
    "        \n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self, seed: int = None):\n",
    "        \"\"\" \n",
    "        Reset the parameters to some random values.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        seed : int, optional\n",
    "            Seed for random initialisation.\n",
    "        \"\"\"\n",
    "        rng = np.random.default_rng(seed)\n",
    "        self.w = rng.standard_normal(size=self.w.shape)\n",
    "        if self.use_bias:\n",
    "            self.b = np.zeros_like(self.b)\n",
    "        \n",
    "    def compute_outputs(self, x):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : (N, Ci, H, W) ndarray\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        feature_maps : (N, Co, H', W') ndarray\n",
    "        cache : ndarray or tuple of ndarrays\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        output = multi_channel_convolution2d(x, self.w)\n",
    "        if self.use_bias:\n",
    "            output += self.b\n",
    "        \n",
    "        return output, x\n",
    "        \n",
    "        \n",
    "    \n",
    "    def compute_grads(self, grads, cache):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        grads : (N, Co, H', W') ndarray\n",
    "        cache : ndarray or tuple of ndarrays\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        dx : (N, Ci, H, W) ndarray\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "        # The following is now based on the slides at page 26-48\n",
    "\n",
    "        # dx = None\n",
    "\n",
    "        # padding the grads (these are the deltas)      \n",
    "\n",
    "        N, Co, H_prime, W_prime = grads.shape\n",
    "        print(f'N = {N}, Co = {Co}, H_prime = {H_prime}, W_prime = {W_prime}')\n",
    "\n",
    "        px, py = self.kernel_size\n",
    "        px = px - 1\n",
    "        py = py - 1\n",
    "\n",
    "        padded_grads = np.pad(grads, ((0, 0), (0, 0), (px, px), (py, py)), mode='constant', constant_values=0) # no padding in axis 0, 1; constant padding in axis 2, 3\n",
    "\n",
    "        # flipped_w = self.w.transpose(1, 0, 2, 3) # flip along the first diagonal (lecture 15.11. at the end)\n",
    "        flipped_w = np.flip(self.w, axis=(2,3)).transpose(1,0,2,3)\n",
    "        # flipped_w = np.flip(self.w, axis=(2,3))\n",
    "        \n",
    "\n",
    "        print(f'Shape of flipped_w {flipped_w.shape}')\n",
    "        print(f'Shape of padded_grads {padded_grads.shape}')\n",
    "        dx = multi_channel_convolution2d(padded_grads, flipped_w) # flip along the second diagonal\n",
    "        dx = np.flip(np.flip(dx, axis=2), axis=3)\n",
    "        # dx has now the shape (N, Co, H', W')\n",
    "\n",
    "        # right shape but still wrong values\n",
    "\n",
    "        \n",
    "        \n",
    "        # Correct\n",
    "        print(f'Shape of cache {cache.shape}')\n",
    "        print(f'Shape of grads {grads.shape}')\n",
    "        dw = multi_channel_convolution2d(cache.transpose(1, 0, 2, 3), grads.transpose(1, 0, 2, 3)).transpose(1, 0, 2, 3)\n",
    "        self.w.grad = dw        \n",
    "        \n",
    "\n",
    "        # Correct\n",
    "        if self.use_bias:\n",
    "            self.b.grad = np.sum(grads, axis=(0,2,3)).reshape(self.b.shape)\n",
    "                \n",
    "        assert dx.shape == cache.shape, \"Wrong shape of dx\"\n",
    "        assert self.w.grad.shape == self.w.shape, \"Wrong shape of W.grad\"\n",
    "        assert self.b.grad.shape == self.b.shape, \"Wrong shape of b.grad\"\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c5c3a60de9f79d3a4cf66bcda6263428",
     "grade": true,
     "grade_id": "cell-49d5bffe69b5f38d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!\n",
    "conv = Conv2d(3, 8, (5, 3))\n",
    "parameter_names = dict(conv.named_parameters())\n",
    "assert \"w\" in parameter_names, (\n",
    "    \"ex3: Conv2d module does not have 'w' parameter\"\n",
    ")\n",
    "assert \"b\" in parameter_names, (\n",
    "    \"ex3: Conv2d module does not have 'b' parameter\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8658ef83686ea754a3b0e275f7e2ead9",
     "grade": true,
     "grade_id": "cell-2dc8a656c40a0a4d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!\n",
    "x = rng.normal(size=(15, 3, 13, 13))\n",
    "s, cache = conv.compute_outputs(x)\n",
    "assert isinstance(s, np.ndarray), (\n",
    "    \"ex3: output of Conv2d.compute_outputs is not a numpy array\"\n",
    ")\n",
    "assert s.shape == (len(x), conv.out_channels, 9, 11), (\n",
    "    \"ex3: output of Conv2d.compute_outputs has incorrect shape\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ae4c6db37301be3cdfe6f0ad00e8102",
     "grade": true,
     "grade_id": "cell-7bb500eae7ef2b0a",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 15, Co = 8, H_prime = 9, W_prime = 11\n",
      "Shape of flipped_w (3, 8, 5, 3)\n",
      "Shape of padded_grads (15, 8, 17, 15)\n",
      "Shape of cache (15, 3, 13, 13)\n",
      "Shape of grads (15, 8, 9, 11)\n"
     ]
    }
   ],
   "source": [
    "# Test Cell: do not edit or delete!\n",
    "conv.zero_grad()\n",
    "g = conv.compute_grads(np.ones_like(s), cache)\n",
    "assert isinstance(g, np.ndarray), (\n",
    "    \"ex3: output of Conv2d.compute_grads is not a numpy array\"\n",
    ")\n",
    "assert g.shape == x.shape, (\n",
    "    \"ex3: output of Conv2d.compute_grads has incorrect shape\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "120598732c5bee457300f4b544c0b00c",
     "grade": true,
     "grade_id": "cell-c336f1ebc100598e",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!\n",
    "assert np.nonzero(conv.w.grad), (\n",
    "    \"ex3: Conv2d.compute_grads does not compute gradients for 'w' parameter\"\n",
    ")\n",
    "assert np.nonzero(conv.b.grad), (\n",
    "    \"ex3: Conv2d.compute_grads does not compute gradients for 'b' parameter\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e954fcb16a64dacbdc15643231f11493",
     "grade": true,
     "grade_id": "cell-9c971610ce9b4f9b",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 15, Co = 8, H_prime = 9, W_prime = 11\n",
      "Shape of flipped_w (3, 8, 5, 3)\n",
      "Shape of padded_grads (15, 8, 17, 15)\n",
      "Shape of cache (15, 3, 13, 13)\n",
      "Shape of grads (15, 8, 9, 11)\n",
      "51.32921617910954 > 2e-06\n",
      "dx numeric:  [[[[ 2.11691474e+00  1.94761395e+00 -5.00741302e+00 ...  1.36050033e+00\n",
      "    -1.70434586e+00 -6.79629153e-01]\n",
      "   [ 6.44994418e+00  2.49749070e+00  5.05847908e+00 ... -6.51061697e-01\n",
      "     7.87579154e-01 -3.31968681e+00]\n",
      "   [ 1.84335050e-01 -1.04309418e+01  4.52978952e-02 ... -4.80527598e+00\n",
      "     6.03622524e+00  3.35047662e+00]\n",
      "   ...\n",
      "   [-1.30010739e+00 -1.02218526e+01  2.18738353e+00 ...  1.49302720e+01\n",
      "    -4.30588975e+00  3.20219786e+00]\n",
      "   [ 2.94529104e+00  4.41622464e+00 -6.80626346e+00 ...  1.26665448e+01\n",
      "    -1.50886063e+00  1.33817082e-01]\n",
      "   [-2.00361606e+00  3.11124256e+00  3.46469307e-01 ...  8.43659393e+00\n",
      "     2.77895165e+00 -3.79179198e-01]]\n",
      "\n",
      "  [[-3.05178690e+00  1.04381797e+01  8.12409382e-01 ... -4.11556158e-01\n",
      "     3.71413427e+00 -1.96633218e+00]\n",
      "   [-4.17306194e+00  9.87992536e+00  7.90763781e+00 ... -1.09628130e+01\n",
      "    -6.37032929e+00 -1.54154949e+00]\n",
      "   [-1.03937867e+01 -1.70472842e+00  1.09799828e+01 ...  3.96760038e+00\n",
      "     1.04996502e-01  7.22531587e+00]\n",
      "   ...\n",
      "   [-3.11544198e-01  7.09645053e+00  6.73500489e+00 ... -4.98302978e+00\n",
      "    -7.53091987e+00  2.92519820e+00]\n",
      "   [ 4.08662333e+00 -1.79073228e+00 -2.49210302e-01 ... -8.30943003e+00\n",
      "     9.98991453e-01 -5.31534641e+00]\n",
      "   [ 1.51638116e+00 -2.25070121e+00  2.70347670e+00 ...  6.68623133e+00\n",
      "    -9.88816907e-01 -1.63504663e+00]]\n",
      "\n",
      "  [[ 2.17702845e+00 -2.71786698e+00 -1.21997067e+00 ... -2.11402923e+00\n",
      "    -1.57583381e+00 -2.47982163e+00]\n",
      "   [ 3.63523932e+00  1.89845295e+00 -9.04289493e+00 ... -2.16403964e+00\n",
      "    -8.20900965e+00  4.05340364e+00]\n",
      "   [ 5.80061487e+00 -1.08966418e+00 -1.40216041e+01 ... -1.70019338e+01\n",
      "    -5.11389894e+00  8.47405644e+00]\n",
      "   ...\n",
      "   [-1.82050437e+00  2.46020403e+00  2.92906293e-01 ... -2.83457481e+00\n",
      "    -1.23480922e+00 -7.38501100e+00]\n",
      "   [-5.80425365e-01  3.75635778e-01  2.26975737e+00 ...  2.71191561e+00\n",
      "     5.35403183e+00 -3.08088002e+00]\n",
      "   [ 3.87471800e-01 -1.15123686e+00 -7.82101637e-01 ... -8.90693258e+00\n",
      "    -1.63593930e+00  3.02651645e+00]]]\n",
      "\n",
      "\n",
      " [[[ 3.67624324e-01 -1.84442149e+00  2.27241122e+00 ... -3.79197931e+00\n",
      "     1.08292048e+00  1.36007841e+00]\n",
      "   [ 3.89307863e+00  1.61024022e+00  1.92963506e+00 ... -6.74464991e+00\n",
      "    -1.82325022e+00 -1.00541092e+00]\n",
      "   [-8.56132374e-01 -1.29370370e+01  1.68429924e+01 ...  2.95792424e+00\n",
      "     1.54868530e-01 -5.69202280e+00]\n",
      "   ...\n",
      "   [ 3.01331809e+00  3.77885257e+00 -4.00859901e+00 ... -1.63650148e+01\n",
      "     1.20541759e+00 -3.96658714e+00]\n",
      "   [-1.02975051e+00  1.61019483e+00  4.62010476e+00 ...  1.58101977e+01\n",
      "     7.17197943e+00  5.03892332e+00]\n",
      "   [ 9.56728343e-01 -2.66409609e+00 -2.45777957e+00 ...  8.24936876e-01\n",
      "    -8.05150341e+00 -2.85085184e+00]]\n",
      "\n",
      "  [[-2.43992199e+00  8.97330378e+00  5.47948676e+00 ...  5.77867587e+00\n",
      "    -7.57926355e+00 -6.29942414e+00]\n",
      "   [-1.90646830e+00  2.54422042e+00  6.32917994e+00 ...  5.74022280e+00\n",
      "    -6.36721668e+00 -1.00561546e+01]\n",
      "   [-1.15785450e+01 -1.37895892e+01  1.76740815e+00 ...  3.48433167e+00\n",
      "    -3.16661095e+00 -3.92442473e-01]\n",
      "   ...\n",
      "   [-4.95687513e+00  1.28454971e+00 -8.37715169e+00 ...  1.61841677e+01\n",
      "     2.94643840e+00  8.00507550e+00]\n",
      "   [ 1.39410275e+00 -3.27928007e+00  2.32836399e+00 ...  1.08250078e+01\n",
      "     4.88171159e+00  2.26054806e+00]\n",
      "   [ 3.13262399e+00 -1.04334111e+00  9.43518188e-01 ...  2.75433126e+00\n",
      "    -4.89947041e+00  1.22066859e+00]]\n",
      "\n",
      "  [[-2.75486457e-01  1.73245914e+00  5.93712792e+00 ...  1.89219389e+00\n",
      "     5.93013291e+00 -1.36760951e+00]\n",
      "   [ 2.75980705e+00 -4.91540374e+00  5.71783511e+00 ... -1.68537417e+00\n",
      "    -3.62262659e+00  1.38802542e+00]\n",
      "   [-8.49112780e-02 -1.44665222e+00 -9.53153574e-01 ... -3.49592989e+00\n",
      "     7.98352167e+00  1.03836161e+01]\n",
      "   ...\n",
      "   [-1.43956413e+00  6.87320551e-01  5.38675033e+00 ... -1.44429663e-01\n",
      "    -2.76943746e+00  7.63253914e+00]\n",
      "   [ 6.49801621e-01 -5.49405144e+00  2.06631006e+00 ... -2.70200675e+00\n",
      "    -6.80777848e+00 -7.07130829e+00]\n",
      "   [ 5.52355675e+00 -8.71916569e-01 -1.28573726e+00 ... -4.00063169e+00\n",
      "     3.42199414e+00  1.83464817e+00]]]\n",
      "\n",
      "\n",
      " [[[-1.32595886e-01  2.53433174e+00  4.82711164e+00 ... -3.84764252e+00\n",
      "     7.05131782e-01  1.76391097e-02]\n",
      "   [ 2.55767475e+00 -2.02153046e-01  3.56569831e+00 ...  4.17742083e+00\n",
      "     5.21468044e+00 -4.41938303e+00]\n",
      "   [ 1.50274886e+00 -1.18456354e+01 -7.71821283e+00 ...  2.33893900e-01\n",
      "    -4.50089760e+00 -6.06715389e-01]\n",
      "   ...\n",
      "   [ 1.65518713e-01  8.50826990e+00  5.46820891e+00 ...  6.45276765e+00\n",
      "     6.90889428e+00  2.39464006e+00]\n",
      "   [-2.61781247e+00  1.14860752e+01 -5.54112256e+00 ...  7.66736420e+00\n",
      "     3.50465174e+00  1.20563701e+00]\n",
      "   [-1.49155204e+00  3.91811361e+00 -8.17836994e+00 ... -3.32665172e+00\n",
      "    -3.14627286e+00 -3.69488390e-01]]\n",
      "\n",
      "  [[-1.90461463e-01 -4.67603149e+00 -5.12681933e+00 ...  5.40789870e+00\n",
      "     7.50539510e+00  6.58223314e-01]\n",
      "   [ 3.85405338e+00  1.39008716e+00 -1.55186612e+00 ...  1.56124503e+00\n",
      "     6.21448555e+00 -8.96545203e-01]\n",
      "   [ 8.29248819e+00  1.56081370e+00 -1.07445268e+01 ... -8.38562437e+00\n",
      "    -4.55050562e+00 -2.04053384e+00]\n",
      "   ...\n",
      "   [ 5.65402416e-01 -7.24229184e+00  5.10011148e-01 ... -3.92416791e+00\n",
      "     1.70518126e+00 -3.09588290e+00]\n",
      "   [-2.50525980e+00  4.02594580e+00 -8.71389256e+00 ...  2.31213653e+00\n",
      "     1.12011679e+00 -2.32973602e+00]\n",
      "   [-1.60777802e-01  8.41215950e-01 -2.47513543e+00 ...  7.03379681e+00\n",
      "    -4.69462165e+00  3.11519469e+00]]\n",
      "\n",
      "  [[-2.08149771e+00  1.03709351e+00 -7.45430668e+00 ... -1.68161978e+00\n",
      "     1.43861322e+00 -9.34634261e+00]\n",
      "   [ 2.43624811e-01  2.74393267e+00 -1.33955115e+01 ...  1.01757259e+01\n",
      "    -2.94610587e+00  9.93877742e+00]\n",
      "   [ 4.07265304e-01 -5.24420591e+00 -2.52272818e+00 ... -1.21223934e+01\n",
      "     1.07203761e+00  6.77791149e-01]\n",
      "   ...\n",
      "   [-1.58266857e-02  3.63677529e+00  3.73630039e+00 ... -7.58360272e-01\n",
      "    -4.94110043e+00 -3.74092332e+00]\n",
      "   [-6.44318163e-02 -1.62114225e+00 -2.37453253e+00 ... -2.39476338e+00\n",
      "    -4.94562389e+00 -3.70508218e+00]\n",
      "   [-1.27783790e+00  2.77794845e+00 -1.36220456e+00 ...  2.79310498e+00\n",
      "     3.26801424e+00 -4.73746411e-01]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 4.21838990e-02 -1.15447359e+00  5.57527926e+00 ... -5.79875790e+00\n",
      "    -4.42896351e-01  1.96642853e+00]\n",
      "   [-1.84169491e+00 -1.05954712e+00 -1.49817048e+00 ...  1.10209359e+01\n",
      "    -4.13626736e+00  6.75303852e-01]\n",
      "   [ 4.32122363e-01 -3.37484119e+00 -9.36190459e+00 ... -2.49203111e+00\n",
      "    -1.15621653e+01 -2.19445907e+00]\n",
      "   ...\n",
      "   [-3.65907779e+00  9.98557439e-01 -4.59791471e+00 ...  1.30641426e+00\n",
      "     4.47123085e-02  6.08853966e-01]\n",
      "   [ 1.67182445e+00 -4.68102228e+00  2.12536818e-01 ...  1.45736509e+01\n",
      "     5.86243462e+00 -2.09274305e-02]\n",
      "   [ 2.95847632e+00 -7.40509070e+00 -1.78901200e+00 ... -6.73382721e+00\n",
      "     1.46865446e+00  4.80251472e-01]]\n",
      "\n",
      "  [[ 3.72295300e+00 -3.91056705e+00 -9.32108406e+00 ...  4.55867874e+00\n",
      "    -2.48654733e+00 -5.49536729e+00]\n",
      "   [-4.09451667e+00 -1.19746859e+00 -3.09422322e+00 ... -3.55823228e+00\n",
      "    -1.82327862e+01 -2.39743905e+00]\n",
      "   [ 3.46195890e-02  9.47301174e-01  9.64156125e+00 ...  2.23367960e+00\n",
      "    -1.00904124e+01  5.94103982e+00]\n",
      "   ...\n",
      "   [ 1.41237825e+00  6.56038839e+00 -4.13582474e+00 ... -2.65454540e+00\n",
      "     1.19797247e+01 -2.34828704e+00]\n",
      "   [ 1.78089965e+00  8.70160605e-01  1.30030587e+01 ...  1.15024695e+01\n",
      "     2.14702035e+00 -6.98605731e-01]\n",
      "   [-1.11369346e-01  2.65706775e+00  4.96389987e+00 ... -7.25043182e+00\n",
      "    -3.84070842e+00  3.22989945e+00]]\n",
      "\n",
      "  [[ 9.83323503e-01 -3.73044372e-01 -9.26762388e+00 ... -1.17889627e+00\n",
      "     2.08956246e+00 -5.61555268e+00]\n",
      "   [-1.57065087e+00 -1.10011827e+00 -1.34552684e+00 ... -3.76821475e+00\n",
      "     2.27337871e+00  5.25082859e+00]\n",
      "   [-2.03332733e+00  2.27773282e+00  6.34327097e+00 ... -1.82155594e+01\n",
      "     4.04442919e+00  5.11929427e+00]\n",
      "   ...\n",
      "   [ 1.82347553e+00 -5.76675657e+00  4.75664457e+00 ...  2.98381245e+00\n",
      "    -8.02286881e+00  7.16353553e+00]\n",
      "   [ 1.83188246e+00 -1.21613226e-02  1.11766443e+00 ... -7.11885359e+00\n",
      "    -3.54074413e+00  3.66382456e+00]\n",
      "   [ 2.96592957e+00 -2.51359310e-01  5.15451171e+00 ...  4.26565147e+00\n",
      "    -1.23743393e+00 -5.40899237e-03]]]\n",
      "\n",
      "\n",
      " [[[ 9.95947701e-01 -2.72777834e+00  4.01185837e+00 ...  2.50391523e+00\n",
      "    -1.52286512e+00 -5.59541178e-02]\n",
      "   [-2.52733285e+00 -4.11379297e+00 -5.81937992e+00 ... -3.17075038e+00\n",
      "     3.45580384e+00 -4.28867494e-01]\n",
      "   [-4.77907312e+00 -2.21319804e+00  4.89722387e+00 ... -8.10770584e+00\n",
      "     8.67554085e+00  3.12925259e+00]\n",
      "   ...\n",
      "   [-2.19997189e+00  4.66582775e+00 -3.10336063e-01 ...  1.69383606e+01\n",
      "    -9.85697929e+00  6.47151293e+00]\n",
      "   [ 1.68846667e+00  5.81715993e+00 -9.31017421e+00 ...  2.00049868e-01\n",
      "    -8.61640325e+00 -3.24940910e+00]\n",
      "   [ 3.50622770e+00 -2.72414493e+00 -2.41274235e+00 ... -9.85866097e+00\n",
      "     4.83875473e+00  3.92291174e+00]]\n",
      "\n",
      "  [[-3.07399858e-01  1.43659832e-01  5.75847992e+00 ... -5.92429650e+00\n",
      "     6.67076847e-01  3.13796630e+00]\n",
      "   [-7.42554016e+00 -3.50316390e+00 -1.13083471e+01 ...  2.87319934e+00\n",
      "     2.56357552e+00  6.78582231e+00]\n",
      "   [-3.48595815e+00  3.99865411e+00  3.54808489e+00 ... -1.94992792e+00\n",
      "     6.98515439e+00  3.85481238e+00]\n",
      "   ...\n",
      "   [-7.17323597e+00  1.62523078e+00  8.61142027e-01 ...  9.42313119e+00\n",
      "    -1.03795742e-01 -5.16594827e+00]\n",
      "   [-4.63695096e+00  2.38822452e+00 -2.03744287e+00 ...  3.78456905e+00\n",
      "    -1.05135191e+01  6.42195592e+00]\n",
      "   [-3.20258943e+00  7.12112609e-01  6.00583732e-01 ...  1.45130096e+00\n",
      "    -3.64389120e+00  6.52578876e-01]]\n",
      "\n",
      "  [[-2.29247827e+00  3.13927578e+00  2.06764838e+00 ... -6.01818731e+00\n",
      "     8.27927536e-01  1.97008825e+00]\n",
      "   [-2.19478096e+00  6.36147816e+00 -7.83195495e+00 ...  1.44604228e+00\n",
      "     6.08993597e+00  2.81637078e+00]\n",
      "   [ 3.24312268e-01 -1.06511825e+01 -1.05638158e+00 ... -7.76103201e+00\n",
      "     5.99228784e-01 -6.90394302e-02]\n",
      "   ...\n",
      "   [-4.38048390e+00  1.16981666e+01 -1.12189069e+01 ...  6.80848420e+00\n",
      "    -8.23997993e-01  2.27099848e+00]\n",
      "   [ 8.45164365e-01  8.43481004e-01 -8.52806636e-01 ... -1.10227179e+01\n",
      "     9.31631803e-01  3.60356506e+00]\n",
      "   [-6.42511679e-01  1.15109242e+00  2.05931315e-01 ... -7.65618239e-01\n",
      "    -3.97071955e+00 -1.91231932e+00]]]\n",
      "\n",
      "\n",
      " [[[ 1.99854136e+00 -1.09211248e+00 -1.72674264e+00 ...  2.73602758e+00\n",
      "    -8.48998269e-01  1.46917635e+00]\n",
      "   [-6.11497535e+00 -3.75218879e+00  9.15029517e+00 ... -6.02881926e-01\n",
      "     3.54831172e-01 -9.46160114e-01]\n",
      "   [-3.43361918e-01  8.06023544e+00  1.04438979e+01 ... -1.27420524e+01\n",
      "     5.32488484e+00 -3.64344008e+00]\n",
      "   ...\n",
      "   [ 1.70200944e+00  2.23022033e+00 -1.64626597e+01 ... -1.25801216e+00\n",
      "     5.00199808e+00 -6.35357370e+00]\n",
      "   [-8.29651583e-02 -5.87372088e+00  5.87396414e-01 ...  2.72821995e+00\n",
      "    -2.63491376e+00 -3.88785838e+00]\n",
      "   [ 2.56828099e+00  2.85502863e+00  5.43955933e+00 ... -3.28217513e+00\n",
      "    -1.40098531e+00 -8.95411347e-01]]\n",
      "\n",
      "  [[-8.04640091e+00  1.64725037e-01  5.69489301e+00 ... -4.99069077e+00\n",
      "    -2.39566950e+00 -2.54475765e+00]\n",
      "   [-1.08549034e+01  3.75166131e+00  2.69792029e+00 ... -1.98560324e+01\n",
      "    -6.54079111e+00 -4.13917330e+00]\n",
      "   [-1.22126116e+01  8.28084438e+00 -1.30055498e+00 ...  1.63110643e+00\n",
      "     8.87250009e+00  2.83309625e+00]\n",
      "   ...\n",
      "   [-1.14211056e+01  5.58899742e-01 -7.84091631e+00 ...  1.87571549e+01\n",
      "     3.02163342e+00 -1.28130561e+00]\n",
      "   [-2.42959361e+00  4.25701288e-01 -1.23673438e+01 ...  1.02564208e+01\n",
      "    -2.79598993e-01 -5.38725331e-01]\n",
      "   [ 3.23066884e+00  5.21525635e-01  1.47731626e+00 ...  2.24429930e+00\n",
      "    -1.30913615e+00 -8.78265752e-01]]\n",
      "\n",
      "  [[-6.06628765e+00 -3.75196198e+00  7.07625892e+00 ... -4.41012945e+00\n",
      "     2.92589405e-01 -4.31285699e-01]\n",
      "   [-5.72679625e-01  2.18028676e+00 -3.65719799e+00 ...  1.16358352e+00\n",
      "     5.20546990e+00 -9.17661453e-01]\n",
      "   [-2.27185566e+00 -4.19973139e+00 -9.15078398e+00 ...  3.09116061e-01\n",
      "     8.14458619e+00 -8.27442553e+00]\n",
      "   ...\n",
      "   [ 1.79565787e+00 -2.80639195e+00  6.57219709e+00 ... -4.05591547e+00\n",
      "    -3.52632679e+00  1.57975576e+00]\n",
      "   [-1.12534099e+00  7.53890177e-01 -9.07541690e-01 ... -5.05392549e+00\n",
      "     3.91325676e+00  3.93152565e+00]\n",
      "   [ 2.20738310e+00 -2.48894438e-01 -2.28895978e+00 ...  5.64677563e-01\n",
      "    -2.42655011e+00  8.23971874e-01]]]]\n",
      "dx analytic: [[[[ 9.76775993e-01 -7.02832889e-01 -1.21574724e+01 ... -3.60041363e-02\n",
      "    -2.44187615e+00 -1.46970375e+00]\n",
      "   [-2.90629385e+00  6.85808221e-01 -6.69751694e+00 ... -1.87838442e+00\n",
      "    -2.99810972e+00  6.52892345e-01]\n",
      "   [-3.63465019e+00  7.02364638e+00 -8.66168909e+00 ...  7.74859166e+00\n",
      "    -3.11034034e+00 -1.28138686e+01]\n",
      "   ...\n",
      "   [-7.63023750e+00 -4.06583617e+00  2.48975954e+00 ... -7.49331997e+00\n",
      "     1.45841386e+01 -3.32580906e+00]\n",
      "   [-1.94613209e+00  6.68530221e+00 -4.58544302e+00 ... -1.01614528e-01\n",
      "    -3.48686037e+00  9.42050102e-01]\n",
      "   [ 3.49835930e+00 -7.25504427e+00  2.55100907e+00 ...  3.31106224e+00\n",
      "     3.25589111e+00  9.51971616e-01]]\n",
      "\n",
      "  [[-1.47222234e+00  2.58133150e+00  1.71303662e+00 ...  1.36448978e-01\n",
      "     2.52595109e+00 -1.46562948e+00]\n",
      "   [-5.31716618e+00  1.59718653e+00 -5.73926750e+00 ...  3.48393552e+00\n",
      "    -1.29816302e+00  3.98754157e+00]\n",
      "   [-6.28200284e+00  3.13199334e-02  4.54921867e+00 ... -4.94966234e+00\n",
      "     1.33109405e+01  2.97075921e+00]\n",
      "   ...\n",
      "   [ 2.48962388e+00  9.73578724e+00 -1.69540418e+01 ...  8.57158613e+00\n",
      "     1.21780820e+01  1.82033989e+01]\n",
      "   [ 3.31208420e+00 -7.16181686e+00 -7.61630295e+00 ... -7.38904065e+00\n",
      "     6.43183873e+00 -1.72525984e+00]\n",
      "   [ 2.13085327e-02 -3.56438218e+00 -9.31868958e+00 ... -7.42816074e-01\n",
      "    -6.44173947e-01 -2.01244102e+00]]\n",
      "\n",
      "  [[ 7.84927990e-01 -4.02735458e+00 -8.15703845e+00 ...  2.05281634e+00\n",
      "     4.91693970e+00  1.98601515e+00]\n",
      "   [-4.40069851e+00  1.83228521e+00  8.04934156e+00 ...  4.22544344e+00\n",
      "    -2.92899881e-01 -2.60839258e+00]\n",
      "   [-1.33804040e+01  4.84437429e+00  1.80880434e+00 ...  6.32789216e+00\n",
      "     9.81715302e+00  6.63175177e+00]\n",
      "   ...\n",
      "   [-1.79994090e+00  2.44652804e+00  3.05109378e+00 ...  3.62812443e+00\n",
      "    -6.11510363e-01 -1.28186061e+00]\n",
      "   [ 1.70977652e+00 -4.66504101e+00  1.60087939e+00 ... -7.98792692e+00\n",
      "    -9.18748159e-01 -4.14846378e+00]\n",
      "   [-3.30852238e-01 -2.48374284e+00 -8.65373260e+00 ... -1.35338819e+00\n",
      "    -9.79153171e-01 -4.61671868e+00]]]\n",
      "\n",
      "\n",
      " [[[ 2.86968085e+00 -6.80398495e-01 -1.92367907e+00 ... -7.47962113e-02\n",
      "    -1.03076347e+00  6.62482867e+00]\n",
      "   [-6.29807692e+00 -4.88983589e+00  6.70496156e+00 ... -1.06739708e+01\n",
      "     9.68558286e+00 -6.40248226e+00]\n",
      "   [ 3.74324180e+00  4.20011303e+00 -1.12972438e+01 ... -9.00650736e+00\n",
      "    -1.25967387e+00  4.33931397e+00]\n",
      "   ...\n",
      "   [ 2.06975390e+00  7.89158063e+00 -3.45902204e+00 ...  1.52964440e+01\n",
      "     1.14842325e+01  3.68933413e+00]\n",
      "   [ 2.08532714e+00  8.56907096e+00 -4.33089282e-01 ...  9.57823874e+00\n",
      "    -9.47114380e+00  5.21552047e+00]\n",
      "   [ 2.68570562e+00  1.33156143e+00 -1.06267764e+00 ...  2.80724467e+00\n",
      "     8.17258555e-01 -1.54169674e+00]]\n",
      "\n",
      "  [[ 1.36402416e+00 -5.19487797e+00  5.19967518e+00 ...  8.71764839e-01\n",
      "    -1.45337247e+00 -3.22450484e+00]\n",
      "   [-2.38179502e+00 -6.52227071e+00 -1.12168563e+01 ...  9.66978240e+00\n",
      "    -6.94362010e+00  1.33886609e+00]\n",
      "   [ 3.67642861e+00  9.06955457e-01 -1.22555947e+01 ... -1.57773247e+01\n",
      "     1.14982898e+01 -1.05954946e+01]\n",
      "   ...\n",
      "   [-5.78544838e+00 -2.92286843e-01  4.03881749e+00 ... -8.83324124e+00\n",
      "     2.04879726e+00  1.47594681e+01]\n",
      "   [ 2.24294911e+00 -4.44818737e+00  2.61110419e+00 ... -8.79714625e+00\n",
      "     1.41723383e+01 -2.06669082e+00]\n",
      "   [ 2.33290144e+00 -2.13282273e-01  1.44725120e+00 ... -8.72000586e+00\n",
      "     6.55839016e-01  2.45824974e+00]]\n",
      "\n",
      "  [[-1.97965811e+00  8.14067948e-03  2.69003888e-01 ... -4.78194507e-01\n",
      "     4.11813568e-01 -4.86452150e+00]\n",
      "   [-1.79124473e+00 -1.98240275e-01  1.44713153e+01 ... -1.18242419e+01\n",
      "     1.10018461e+01  9.52024249e-01]\n",
      "   [ 1.16425770e+01  1.36324784e+00 -3.84909587e+00 ...  1.53814060e+01\n",
      "    -2.14487236e+00  2.34725020e+00]\n",
      "   ...\n",
      "   [-1.16192785e+00  8.83084890e+00 -1.42240504e+01 ...  1.63836633e+01\n",
      "     9.13885398e+00 -4.22469811e+00]\n",
      "   [-1.86026624e+00 -3.42086902e+00  1.99321871e+00 ... -1.74208742e+00\n",
      "    -8.09271815e+00 -3.05142832e+00]\n",
      "   [-2.44509791e+00 -9.60007901e-01 -1.70484386e+00 ...  7.07089311e+00\n",
      "    -1.34311837e+00 -1.12254292e+00]]]\n",
      "\n",
      "\n",
      " [[[-1.61770124e+00 -1.92199363e+00  3.71904298e+00 ...  1.22219548e+00\n",
      "    -1.98278853e+00 -3.80009411e+00]\n",
      "   [-4.01650666e+00  5.12352756e+00 -2.24816586e+00 ...  2.22926072e+01\n",
      "    -3.99785499e+00 -2.56246710e+00]\n",
      "   [-9.41888496e-01 -5.83106473e+00 -2.39960240e+00 ...  8.47125854e+00\n",
      "     8.78522373e-01 -1.92358815e+00]\n",
      "   ...\n",
      "   [-7.17833596e-02 -4.51481499e-01 -8.02320451e+00 ...  5.77962906e+00\n",
      "    -1.55069153e+01 -5.70765999e+00]\n",
      "   [-1.09532911e+00 -2.72023273e+00  6.91059655e+00 ... -1.44452559e+00\n",
      "    -3.22056471e+00 -1.37656944e+00]\n",
      "   [-5.52750780e+00  8.03712595e+00 -9.82893013e+00 ...  3.71694070e+00\n",
      "    -6.27386707e+00 -1.64890461e+00]]\n",
      "\n",
      "  [[ 3.41541611e+00 -2.18051047e+00  6.28221117e-01 ... -6.18275816e+00\n",
      "     3.23835729e+00  6.55363597e-01]\n",
      "   [ 3.46299538e+00  1.87460443e+00 -7.99971647e+00 ... -9.43544038e+00\n",
      "     1.33293414e+01 -1.74124130e+00]\n",
      "   [ 8.74910301e-01 -5.38366067e-01 -5.07218991e+00 ...  2.68676685e-02\n",
      "     1.19270958e-02  9.44493831e+00]\n",
      "   ...\n",
      "   [ 3.32616803e+00  1.12892435e+01  7.07616947e+00 ...  3.93258731e+00\n",
      "     6.31175534e+00  7.39461253e+00]\n",
      "   [-1.90234368e+00  5.74009467e+00  1.09564906e+01 ... -1.28695079e+01\n",
      "    -5.53499409e+00 -4.95224268e+00]\n",
      "   [-2.95475634e-02 -5.70828102e+00 -3.78771642e+00 ... -1.47816499e+00\n",
      "    -2.13366612e-01 -2.32630306e+00]]\n",
      "\n",
      "  [[-1.86398669e+00 -1.34045168e+00 -8.19329422e+00 ...  2.07704393e+00\n",
      "    -3.10045979e-01 -2.15080762e+00]\n",
      "   [-1.63790836e-01 -9.84251095e+00 -1.20626040e+01 ...  1.44014619e+01\n",
      "    -8.55268756e-01  1.61446907e-01]\n",
      "   [-3.70708091e+00 -5.63583396e+00 -7.87594183e+00 ...  1.02436630e+01\n",
      "     5.37430250e-01  4.61512176e+00]\n",
      "   ...\n",
      "   [ 2.68932284e+00  3.54096255e+00  1.01973330e+01 ... -1.58017912e-01\n",
      "    -4.93835582e-01  5.85494311e+00]\n",
      "   [ 3.04206048e+00  5.65526504e+00 -5.98050477e+00 ...  1.12886815e+00\n",
      "     2.98781814e-01  6.07531390e+00]\n",
      "   [ 3.40377910e+00  3.12109340e+00 -8.32145304e-01 ... -4.57199027e+00\n",
      "     4.38232843e-01 -2.70207715e-01]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 6.73746856e-01 -5.96734947e+00  6.83270692e+00 ...  4.43763087e+00\n",
      "    -3.41817863e+00 -6.59384939e-01]\n",
      "   [-5.44621307e+00 -1.46681832e+01 -1.27759512e+00 ... -8.11116999e+00\n",
      "     1.23100203e+00 -2.52776180e+00]\n",
      "   [-5.46993817e+00 -1.12345261e+00 -3.06089163e+00 ...  7.69682551e+00\n",
      "     8.83562637e-01 -1.49124696e+00]\n",
      "   ...\n",
      "   [-7.13955532e-01 -5.77454406e-01 -1.43640860e+01 ...  1.11764372e+00\n",
      "    -6.01341312e+00  1.41038920e+00]\n",
      "   [ 4.63754289e+00 -3.74358083e+00  7.89950137e+00 ... -1.78568312e+00\n",
      "     5.48334497e+00 -2.83259548e+00]\n",
      "   [-2.47068393e-01 -9.69352770e+00 -3.20416401e+00 ...  4.42970847e+00\n",
      "    -5.29814898e+00  1.33029273e+00]]\n",
      "\n",
      "  [[ 6.18183730e-01 -3.74063979e+00 -6.13949708e+00 ...  2.43645004e+00\n",
      "    -5.86456086e+00  1.15635619e-01]\n",
      "   [-3.85722294e+00 -1.29466866e+01 -9.82722321e+00 ...  3.36827679e+00\n",
      "    -6.09603447e+00  2.61727205e+00]\n",
      "   [-1.66618490e+00  5.57977151e+00 -1.59360620e+01 ... -3.03320046e-01\n",
      "     1.26514402e+01 -6.06297125e+00]\n",
      "   ...\n",
      "   [-2.05543814e-01  7.47065897e+00 -2.42753895e+00 ... -3.94919662e+00\n",
      "     1.02665568e+01 -4.38327989e+00]\n",
      "   [-5.76001115e+00 -3.10980571e+00 -6.18823801e+00 ... -3.99017907e+00\n",
      "    -8.90321656e+00  7.08413074e+00]\n",
      "   [ 1.30749959e+00  4.86299642e+00 -1.72272564e+00 ... -2.88488006e+00\n",
      "    -2.82050546e+00 -3.55851980e+00]]\n",
      "\n",
      "  [[-2.91314519e+00 -7.67216421e+00 -2.73888378e-01 ... -4.59986833e+00\n",
      "     3.95948992e+00 -4.13361572e+00]\n",
      "   [-4.55474215e+00 -3.09474622e+00 -1.09825253e+01 ... -1.25313466e+01\n",
      "     3.12764772e+00  1.00697531e+00]\n",
      "   [ 6.80325874e-02  3.30544189e+00 -7.40045428e+00 ...  3.40616084e+00\n",
      "     8.11122629e+00 -2.53517562e+00]\n",
      "   ...\n",
      "   [-7.85059504e-01  3.24446718e+00  2.97476224e-01 ... -3.10192465e+00\n",
      "     1.73641156e+00  3.20993605e-01]\n",
      "   [-4.20807633e+00 -3.77307685e+00  5.55825372e+00 ...  1.99432513e+00\n",
      "    -9.91739764e-01  1.02509144e-01]\n",
      "   [-3.41874382e+00  6.77910241e+00 -6.96582195e+00 ... -2.31182295e+00\n",
      "    -1.64953738e+00  1.24310959e+00]]]\n",
      "\n",
      "\n",
      " [[[-3.56120813e+00 -7.13303313e-01  1.09343352e+01 ... -1.15010360e+01\n",
      "     1.02275974e+01  2.78534962e+00]\n",
      "   [ 4.50013803e+00 -2.35798044e+00 -8.54213867e+00 ... -2.31985288e+00\n",
      "    -6.52351413e+00 -8.82305781e+00]\n",
      "   [-4.75986829e+00 -2.49273760e+00  9.29484797e+00 ...  8.61346063e+00\n",
      "     2.63189464e+00  3.62125330e+00]\n",
      "   ...\n",
      "   [-8.35952449e+00 -4.50891850e+00 -1.74395088e+00 ...  6.18496285e+00\n",
      "    -7.58328760e+00 -2.19752124e+00]\n",
      "   [-4.03104224e+00  6.60272275e+00 -9.88740313e+00 ...  1.32158805e+01\n",
      "     2.59240512e+00 -3.01247820e+00]\n",
      "   [ 3.03235825e-01 -6.02859196e+00  3.38803767e-01 ...  2.26534545e+00\n",
      "    -4.02183636e+00  1.03470828e+00]]\n",
      "\n",
      "  [[-3.75246934e+00  3.68231247e+00  2.68544184e+00 ... -4.85853130e+00\n",
      "    -3.90661600e+00  2.21102080e+00]\n",
      "   [ 4.25090748e+00 -5.99475800e+00 -3.86891103e+00 ... -1.14721900e+01\n",
      "    -6.59747662e+00  2.21323781e+00]\n",
      "   [ 6.22117182e+00 -1.31831579e+01  1.81249020e+00 ...  1.03042740e-01\n",
      "    -8.85432491e+00 -1.42484686e+00]\n",
      "   ...\n",
      "   [ 1.10132624e+01  1.07149354e+01  7.72640615e+00 ...  3.67207327e+00\n",
      "     2.80233926e+00  1.18583352e+00]\n",
      "   [-6.39734683e-02 -2.26722190e-01  2.67484424e+00 ... -1.60423274e+00\n",
      "     5.55876509e+00  5.83198793e+00]\n",
      "   [-8.66205567e-01  3.29333818e+00 -1.64808514e+00 ... -6.53198317e+00\n",
      "    -2.84568472e+00 -2.02893974e+00]]\n",
      "\n",
      "  [[ 1.41454716e+00  4.13834043e-01  9.14713420e+00 ... -4.99413631e+00\n",
      "    -7.72809551e+00 -1.78344347e-01]\n",
      "   [ 1.29617482e+00  4.90967677e+00 -4.81904692e+00 ...  6.79283816e+00\n",
      "    -5.00288925e+00  4.08301642e+00]\n",
      "   [ 4.47198242e-01 -8.58944446e+00 -1.28188306e+01 ...  2.14390882e+00\n",
      "    -1.26865442e+00 -2.32586332e+00]\n",
      "   ...\n",
      "   [ 3.45581988e+00 -5.70939315e+00 -1.03512560e+01 ...  1.85841933e+01\n",
      "     5.12997298e+00  4.70942388e-02]\n",
      "   [ 4.60869421e+00 -2.28766426e+00  5.58171512e+00 ... -1.15261565e+00\n",
      "     1.33907345e+00  3.13881385e-01]\n",
      "   [-1.13094637e-01 -2.01690419e+00  2.35869753e+00 ...  4.42736545e+00\n",
      "    -5.46306546e-01 -2.13118626e+00]]]\n",
      "\n",
      "\n",
      " [[[ 2.88548795e+00 -5.55505364e+00  2.18237896e-01 ...  4.98845602e+00\n",
      "    -5.20553196e+00  2.67469201e+00]\n",
      "   [ 3.11219890e+00  1.81362904e+00 -1.65047206e+01 ...  9.75760486e-03\n",
      "     8.00908467e+00 -8.17710121e+00]\n",
      "   [ 1.39727779e+00 -2.24585977e+00 -4.14197955e+00 ...  7.45955044e+00\n",
      "    -3.55095124e+00  2.51600902e+00]\n",
      "   ...\n",
      "   [ 2.74129155e+00  1.53594829e-01 -6.87503573e-01 ... -1.67913348e+01\n",
      "     5.36908315e+00  3.08909270e+00]\n",
      "   [ 4.56791611e+00  9.73219703e-01 -4.99358207e+00 ...  2.70270452e+00\n",
      "     2.01796069e+00  7.24931859e-01]\n",
      "   [ 3.47079022e+00 -5.01846638e+00  2.13401457e+00 ... -6.24603649e-01\n",
      "     1.69382887e-01 -5.32544136e-01]]\n",
      "\n",
      "  [[ 2.28382750e+00 -2.59266625e+00  1.86018933e+00 ...  6.04321517e+00\n",
      "    -3.38283335e+00  1.34097134e+00]\n",
      "   [ 2.14211198e-01  3.36635570e+00 -1.02748907e+01 ... -3.92443024e+00\n",
      "     4.01127765e+00  2.75775654e+00]\n",
      "   [ 1.82223235e+00 -5.93573813e-01 -4.70182086e+00 ... -1.15662776e+01\n",
      "     1.60030468e+00  1.49650517e+00]\n",
      "   ...\n",
      "   [-1.90234769e+00 -1.38522994e+01 -1.21284371e+01 ... -1.08884861e+00\n",
      "    -2.82346511e-01  3.65682100e+00]\n",
      "   [ 5.07399096e-02 -9.95963837e-01 -1.45971287e+00 ...  1.56854094e+00\n",
      "     1.12547035e+01 -1.30388434e+00]\n",
      "   [-6.77185768e-01  6.74065494e-01 -4.45594567e+00 ...  7.47387771e+00\n",
      "     1.03607162e+01  3.95348676e+00]]\n",
      "\n",
      "  [[ 6.08249920e-01 -2.87702576e+00 -4.39867572e+00 ...  4.47660784e+00\n",
      "    -1.64734881e+00 -4.52139165e+00]\n",
      "   [ 3.62967532e-01 -2.64624616e+00 -3.74643837e+00 ... -4.02844440e+00\n",
      "    -2.77231335e+00 -5.76025161e+00]\n",
      "   [ 1.34326797e+00  1.03054082e+01  5.05516240e+00 ... -1.65300018e+01\n",
      "    -2.84200618e+00  8.20381683e-01]\n",
      "   ...\n",
      "   [ 1.55546817e+00 -1.03090626e+01  5.83355131e+00 ... -1.07425343e+01\n",
      "    -9.15451203e+00 -7.91036278e+00]\n",
      "   [ 1.17936380e-01 -8.46512266e+00  3.80752913e+00 ...  1.26289481e+01\n",
      "     1.36522124e+01 -8.57509643e-01]\n",
      "   [-2.59512946e+00 -1.53028538e+00 -3.11621362e+00 ...  1.87606081e+00\n",
      "    -5.35410718e+00 -6.47207026e+00]]]]\n",
      "192.96711820752364 > 2e-06\n",
      "dw numeric:  [[[[ -38.17510589  -29.80615909 -114.74067259]\n",
      "   [  31.63091057   34.60171258  -48.74479865]\n",
      "   [ -13.87474951  -36.51569205    7.87765184]\n",
      "   [  40.28788547   33.96878638  -36.64888887]\n",
      "   [  83.56613901    6.74294118  -42.44573134]]\n",
      "\n",
      "  [[ -40.81646908   54.5173697   -61.20135026]\n",
      "   [ -16.23851014   32.13512498   23.25706279]\n",
      "   [ -26.07387972   -7.08494078  -28.22791697]\n",
      "   [  14.36706295  102.17813356  -21.81386273]\n",
      "   [  -6.21674899   53.16435293  -13.34455207]]\n",
      "\n",
      "  [[   5.97419375    6.4285187     3.45958451]\n",
      "   [  31.71655432    5.65901314    1.9028202 ]\n",
      "   [-124.64778624   55.42319414   13.72953245]\n",
      "   [  21.16134551  -25.79664697   32.20876997]\n",
      "   [ -24.93310896   25.60998654   71.14036782]]]\n",
      "\n",
      "\n",
      " [[[  -6.98010594   58.62745154   14.39959996]\n",
      "   [ -56.39234536  -34.50819044   46.86360782]\n",
      "   [ -32.8302784   -17.17535638   44.68204654]\n",
      "   [   4.78751157   42.08729149  -50.79272219]\n",
      "   [ -42.19568511 -116.54189996   47.2615247 ]]\n",
      "\n",
      "  [[  59.55707593   45.90687607   14.935365  ]\n",
      "   [   3.0032232    46.36738302    0.15999758]\n",
      "   [ -43.95168369  -33.00425665  -29.764865  ]\n",
      "   [ -19.27689759  -23.13498783   -8.96411736]\n",
      "   [ -78.0536332    13.23377991  -45.59037356]]\n",
      "\n",
      "  [[-113.7505033   -43.8781903    -9.95733814]\n",
      "   [ -36.23173602   -0.34793945   36.88161736]\n",
      "   [   1.88290629   39.16092598   53.1564575 ]\n",
      "   [  19.76659939  -13.03575273  -47.34907321]\n",
      "   [  14.78163306  -38.83058662  108.05184549]]]\n",
      "\n",
      "\n",
      " [[[  -0.94830384  -23.4007648    82.83633558]\n",
      "   [  39.92443462   -2.52592415  -34.09197755]\n",
      "   [ -58.6333539   -18.24523208   50.47157244]\n",
      "   [ -37.53556697  -56.72963205  -15.91414137]\n",
      "   [ -12.30206843   36.92563003   14.77384417]]\n",
      "\n",
      "  [[ -42.95909366   -5.9095445    76.48941597]\n",
      "   [  48.3665937    17.58025753  -31.17491219]\n",
      "   [ -28.44673537  -20.78743005  -12.82696674]\n",
      "   [  29.07897353   62.23654776  110.30038901]\n",
      "   [ -17.26291976   31.48271873  -10.91094892]]\n",
      "\n",
      "  [[  21.55832289   24.20567624   -8.52049436]\n",
      "   [ -71.40821337   24.21145373   25.57289999]\n",
      "   [   7.2462705   -38.61215693  -76.22813652]\n",
      "   [-102.8127041    23.13500966    8.43139685]\n",
      "   [ -25.17098095  -58.31052924  -26.47506435]]]\n",
      "\n",
      "\n",
      " [[[  17.48784049   20.07799075   12.63058913]\n",
      "   [ -30.21623287  -26.89896878  -69.15499608]\n",
      "   [  55.3687493   -23.13875399   -4.31459731]\n",
      "   [  -0.42178681   36.90230416   19.30821486]\n",
      "   [ -43.44310565  -24.0795228    20.54408661]]\n",
      "\n",
      "  [[ -40.35574914   74.94086211   -9.04519247]\n",
      "   [ 100.96131467    6.21153829   13.77192504]\n",
      "   [  39.98294528   20.98054178  -18.019789  ]\n",
      "   [  -1.21690944    9.9191968    22.90705537]\n",
      "   [  40.74553804  -59.07765282   -7.25144034]]\n",
      "\n",
      "  [[ -63.20356401  -16.87107516   10.31556835]\n",
      "   [  12.09962069  -40.28654656    3.47868175]\n",
      "   [  29.61054226   20.44640284   17.48145124]\n",
      "   [   6.64629005   42.93116201    9.4107957 ]\n",
      "   [ -54.19272082  -66.28894688    2.80603929]]]\n",
      "\n",
      "\n",
      " [[[  24.7928697   -28.16369071   61.46153554]\n",
      "   [ -41.95777036  -10.72612905  -56.14642487]\n",
      "   [   3.01327729   66.09518647   -5.00782049]\n",
      "   [ -45.21810743    7.45852005  -18.0645437 ]\n",
      "   [  38.44988662    1.5964043   -33.98445034]]\n",
      "\n",
      "  [[ -16.91071543   96.26985901   -6.02823813]\n",
      "   [  -9.73325072  -15.5423904   -47.49985212]\n",
      "   [  -0.27688526   28.05084593   46.46261196]\n",
      "   [ -36.94396212   48.15756179   50.36922411]\n",
      "   [ -34.69481882  -85.65726424   -9.47345035]]\n",
      "\n",
      "  [[   6.6031326    35.92744847   -7.61106503]\n",
      "   [ -26.28705556   34.68057035    4.33303224]\n",
      "   [ -41.95285207  -43.68036161   -8.80906222]\n",
      "   [  22.25993474  -54.16772251    3.06914852]\n",
      "   [  -8.73539389   57.26537772  -13.37753832]]]\n",
      "\n",
      "\n",
      " [[[  52.0782279     3.77928033   -9.44016521]\n",
      "   [  32.70995599  -34.48155711  -29.85344602]\n",
      "   [  43.8015699    -6.74328334    0.61171251]\n",
      "   [  -9.75732998  -30.65422291  -29.33623229]\n",
      "   [ -24.51410828   26.3133664    21.85685761]]\n",
      "\n",
      "  [[ -18.67650673   20.96393365  -29.16526475]\n",
      "   [  14.31634593  -22.11888282   25.23704845]\n",
      "   [  -6.65885985  -40.90453518   -7.65750555]\n",
      "   [ -15.08844332   22.56960066  -33.69701423]\n",
      "   [ -44.00783472   -2.99259065   28.01609899]]\n",
      "\n",
      "  [[   5.6706492   -21.25020299  -15.64996752]\n",
      "   [-110.52054876   18.28808671   22.41265638]\n",
      "   [  44.77068426  -29.44937904   32.43579373]\n",
      "   [ -49.92799437    6.31932791   25.0607752 ]\n",
      "   [  -9.2573966   -30.52806271   16.14724124]]]\n",
      "\n",
      "\n",
      " [[[  43.81286155   33.24458756   41.23379065]\n",
      "   [  74.98127187  -82.00522258    8.901485  ]\n",
      "   [ -40.02833104   76.72750721   -2.28954138]\n",
      "   [ -23.36925188  -40.36704365  -11.94870725]\n",
      "   [ -18.96251992  -14.68234622  -60.73471675]]\n",
      "\n",
      "  [[ -26.84621491    4.75569963   31.02763847]\n",
      "   [ -24.22641018   27.871292    -74.36079164]\n",
      "   [  10.1008692    12.81033538   -6.0795914 ]\n",
      "   [ -15.93525008  -69.25123101    5.28829983]\n",
      "   [  92.74723823  -76.42309538  -16.18987069]]\n",
      "\n",
      "  [[ -84.7119495   -45.30519521  -50.73610764]\n",
      "   [ -31.46440883  -17.24984261   33.97943733]\n",
      "   [ -47.56630294    7.50549496  -39.7810071 ]\n",
      "   [  12.87918823   36.0967485    35.31795085]\n",
      "   [  12.67301316   60.22302239   27.74095334]]]\n",
      "\n",
      "\n",
      " [[[  -0.16230182    7.09288642  -11.56277156]\n",
      "   [ -38.37222754  -26.10692788    1.02423678]\n",
      "   [  11.25919813   23.49914709  -12.70771638]\n",
      "   [  27.16232427  -14.54822119  -39.92661169]\n",
      "   [ -53.09540127   29.71315982  -57.23618945]]\n",
      "\n",
      "  [[ -34.02902196  -63.79799535   19.17824106]\n",
      "   [ -29.28082046   33.21058681    5.8383666 ]\n",
      "   [ -24.40131031   22.91344657  -10.81356237]\n",
      "   [  -2.24340805   52.40622616  -23.55617673]\n",
      "   [ -28.21128109  -38.86577129   21.05929477]]\n",
      "\n",
      "  [[  58.72261757   53.71412772  -73.92610898]\n",
      "   [  -5.54914223   -6.82344522   95.6614858 ]\n",
      "   [  27.49819879  -12.66742507  -53.02245228]\n",
      "   [ -43.41390643   26.68652695   40.01255223]\n",
      "   [ -42.2102213    -6.69086481   -3.38458125]]]]\n",
      "dw analytic: [[[[ 4.14135731e+01  3.64327932e+01 -4.25206648e+01]\n",
      "   [ 1.42445727e+00 -5.85783111e+01  1.16790054e+01]\n",
      "   [-5.68535294e+01  3.95379042e+01  1.52159479e+01]\n",
      "   [ 6.72148041e+01  1.06325854e+01  3.71325052e+01]\n",
      "   [-2.29011084e+00 -2.98178604e+01 -1.91298754e+01]]\n",
      "\n",
      "  [[-1.70545723e+01  6.41259266e+00 -4.15897669e+00]\n",
      "   [ 2.96085786e+01  2.40308392e+01  3.65537740e+00]\n",
      "   [ 1.47768797e-01  3.68569912e+01 -1.33420054e+01]\n",
      "   [ 8.29797556e+01 -7.75400427e+00 -2.62495307e+00]\n",
      "   [-6.53640693e+01  1.87422009e+01 -8.53976129e+00]]\n",
      "\n",
      "  [[ 6.16601533e+01 -3.01653701e+01 -4.24780000e+01]\n",
      "   [ 2.64726412e+01  7.20533258e+01  5.35857681e+00]\n",
      "   [ 5.30817639e+00 -1.13971812e+01  2.08515307e+01]\n",
      "   [ 5.60350599e+01  3.12469322e+01 -1.89249409e+01]\n",
      "   [-2.98285355e+01 -2.47810572e+00  7.40248153e+01]]]\n",
      "\n",
      "\n",
      " [[[-6.02917871e-01  2.12761791e+01  3.18559359e+01]\n",
      "   [ 4.31632323e+01  3.54037104e+01 -4.78157193e+01]\n",
      "   [-3.64048079e+01 -5.36916593e+01  2.16058955e+01]\n",
      "   [ 5.19666270e+00  3.78567155e+01  2.16325612e+01]\n",
      "   [-6.25210142e+01  1.32965617e+01  5.98158852e+00]]\n",
      "\n",
      "  [[ 6.30465857e-01 -1.74319963e+01  5.64011106e+00]\n",
      "   [-6.36467036e+00  1.04665948e+02 -8.60429691e+01]\n",
      "   [ 6.30585173e+01  2.13555170e+01  1.55326196e+01]\n",
      "   [ 6.40699539e+00 -5.89106169e+01  9.18303730e-02]\n",
      "   [ 3.16661215e+01  3.64655673e+00 -1.22308129e+00]]\n",
      "\n",
      "  [[ 6.80958093e+01  4.86692555e+00  1.56190021e+01]\n",
      "   [ 6.59857714e+01  3.88100320e+01  9.05348784e+01]\n",
      "   [ 3.08063282e+00 -6.38503822e+01  5.37577551e+00]\n",
      "   [-2.48160936e+01 -2.76441431e+01  2.50745588e+01]\n",
      "   [ 1.41967517e+01 -3.52691452e+01 -1.69956412e-01]]]\n",
      "\n",
      "\n",
      " [[[-3.76357702e+01  1.10264276e+01 -1.96612033e+01]\n",
      "   [ 9.23309280e+00 -9.55354507e+01  4.88912671e+01]\n",
      "   [-3.69493230e+01  2.34424303e+01  2.01212151e+01]\n",
      "   [ 5.04633705e+01 -5.86070416e+01  6.88382246e+01]\n",
      "   [-1.91960963e+01  5.10238507e+01  2.31911773e+01]]\n",
      "\n",
      "  [[-2.74481998e+01 -6.28992479e+01 -3.24299380e+01]\n",
      "   [-4.30142124e+01  5.66356183e+00  3.97224635e-01]\n",
      "   [-1.14049607e+01  1.33915520e+01  1.46258704e+01]\n",
      "   [-7.99667259e+00 -2.05910331e+01 -7.28931732e+01]\n",
      "   [ 8.07972549e+01  2.39274662e+01 -8.71417677e+00]]\n",
      "\n",
      "  [[ 3.11295715e+01  5.74037535e+00 -1.98293261e+01]\n",
      "   [-4.45696300e+01 -6.18680521e+01 -3.51731884e+01]\n",
      "   [-2.88037227e+01  6.25752835e+01 -2.33760445e+01]\n",
      "   [-2.75795459e+01 -7.82274569e+01  1.36368079e+01]\n",
      "   [ 9.13885614e+01 -4.17015415e+01 -2.37576487e+01]]]\n",
      "\n",
      "\n",
      " [[[-4.36366568e+01  4.63090518e+01 -4.38728950e+00]\n",
      "   [-1.50229637e+01  3.68329716e+01  1.23812122e+02]\n",
      "   [ 5.14884872e+01 -6.63894846e+00  3.97071466e+01]\n",
      "   [ 8.50654267e+01  1.49448426e+01 -6.13034144e+01]\n",
      "   [-3.70058934e+01 -9.42328237e-01 -1.70629023e+01]]\n",
      "\n",
      "  [[ 3.51001319e+01  3.47351261e+01 -2.67504189e+01]\n",
      "   [ 8.21981414e+01  3.97964623e+01  6.66836530e+00]\n",
      "   [ 7.27604118e+01 -4.46824355e+01  9.70514794e+00]\n",
      "   [ 2.98977615e+01  2.69079328e+01 -2.68189199e+01]\n",
      "   [ 8.82694388e+01  3.17385766e+01 -5.58787406e+01]]\n",
      "\n",
      "  [[ 1.68392419e+01 -5.84333876e+00 -3.95989324e+01]\n",
      "   [ 5.97296871e+01 -3.03185180e+01  8.45564116e+01]\n",
      "   [ 8.12874418e+01  5.32070342e+01 -1.46947332e+01]\n",
      "   [ 3.60074114e+01 -5.39289744e+01  2.82277824e+00]\n",
      "   [-2.84099443e+01  1.32969336e+01  6.85530626e+00]]]\n",
      "\n",
      "\n",
      " [[[ 8.62016314e+01  7.62585616e+00  2.50335419e+01]\n",
      "   [ 1.86727830e+01 -2.98386279e+00  4.38257282e+01]\n",
      "   [-1.10464248e+01  1.06334240e+00 -3.27877281e+01]\n",
      "   [ 5.88350805e+01  1.84492479e+01 -3.63404180e+01]\n",
      "   [-5.57352496e+01 -2.51905376e+01  2.17774868e+01]]\n",
      "\n",
      "  [[-1.63055634e+00  3.56417923e+01  4.22584874e+01]\n",
      "   [ 1.07195551e+01 -1.35113676e+01 -4.59318083e+01]\n",
      "   [ 1.71310178e+01  5.79190740e+01  3.24690251e-02]\n",
      "   [-4.18738584e+01 -3.39360209e+01  4.00729890e+01]\n",
      "   [ 1.13576357e+02  3.58415301e+01  4.92189834e+01]]\n",
      "\n",
      "  [[ 4.05610838e+01 -5.15583070e+01 -2.87142503e+01]\n",
      "   [-9.15473998e+00  1.94218462e+01 -4.91470179e+01]\n",
      "   [ 5.12338419e+00 -2.01976327e+01 -1.28102338e+01]\n",
      "   [-6.91193506e+00  5.63233004e+01  9.32621881e+01]\n",
      "   [-3.54928664e+01 -1.28668392e+01 -3.21782602e+01]]]\n",
      "\n",
      "\n",
      " [[[-1.15388708e+01  9.40116974e+01 -5.70097358e+00]\n",
      "   [-1.47995647e+01 -1.35042544e+01  1.84849012e+01]\n",
      "   [ 3.28723701e+01  2.62504646e+01  6.47013486e+01]\n",
      "   [-1.21305022e+01  8.14829951e+00  3.82229956e+01]\n",
      "   [-1.56460373e+01  1.86025933e+01 -9.93892593e+00]]\n",
      "\n",
      "  [[-4.82872389e+01 -3.34430608e+00  3.83478589e+01]\n",
      "   [-5.97406056e+01  3.04726763e+01 -2.97874082e+00]\n",
      "   [-4.22067551e+01 -2.35673894e+01  7.39559167e+01]\n",
      "   [-4.05998433e+01  3.12149470e+01  3.54646028e+01]\n",
      "   [-3.87434628e+01 -6.33708048e+00 -7.28422405e+01]]\n",
      "\n",
      "  [[-1.48956317e+01 -1.54351004e+01  3.81581598e+01]\n",
      "   [-5.84360370e+01  9.24831711e+00 -5.62572810e+01]\n",
      "   [ 3.77864274e+01  6.82176113e+01  1.00399174e+01]\n",
      "   [ 1.81916573e+00  2.60577525e+01 -3.30205779e+01]\n",
      "   [ 2.17053715e+01  2.58295251e+01 -2.27761287e+01]]]\n",
      "\n",
      "\n",
      " [[[ 7.73187841e+00 -2.65919862e+01  1.63482157e+00]\n",
      "   [-3.64711925e+01  8.08342731e+01 -4.74429997e+01]\n",
      "   [ 5.22494873e+01  2.03975118e+01  1.57004434e+01]\n",
      "   [ 9.69338156e+01  5.49095996e+01 -3.73692694e+01]\n",
      "   [ 2.40211374e+01  6.33182138e+00  1.77481507e+01]]\n",
      "\n",
      "  [[-2.85075914e+01  4.42454468e+01 -3.54944250e+01]\n",
      "   [ 1.30435281e+01  1.98939525e+01 -1.44396262e+01]\n",
      "   [-4.32999598e+01 -5.02371545e+01 -5.24148766e+00]\n",
      "   [-6.06356900e+01  4.02104123e+01  1.33165776e+01]\n",
      "   [-1.42797305e+01 -3.80198007e+01  7.13899394e+01]]\n",
      "\n",
      "  [[ 4.24009029e+01 -2.25567668e+01 -1.09873753e+01]\n",
      "   [ 4.93172135e+01  5.15495183e+01  2.24903865e+01]\n",
      "   [ 2.74437767e+01 -3.71213578e+01 -6.15194762e+00]\n",
      "   [-7.75719932e+00 -3.12472081e+01 -7.72779565e+01]\n",
      "   [ 3.00831419e+01  3.74562910e+00  2.78710277e+01]]]\n",
      "\n",
      "\n",
      " [[[-6.54496912e+01  3.37653618e+01 -6.00438244e+00]\n",
      "   [ 3.14866636e+01  1.75776386e+01  4.01685319e+01]\n",
      "   [-6.34152097e+00  2.15063044e+00 -2.11728612e+01]\n",
      "   [-6.58345143e+01 -5.32546372e+00  8.79403916e+00]\n",
      "   [ 3.81188258e+01  4.80129548e+01  1.86617371e+01]]\n",
      "\n",
      "  [[ 1.07393252e+01 -3.12471343e+01 -2.43816938e+01]\n",
      "   [ 1.05875091e+01 -1.29132561e+01  3.39720230e+01]\n",
      "   [ 2.30536643e+01  1.41490815e+01  4.19934943e+01]\n",
      "   [-3.96400554e+01  2.26527931e+01  7.63570072e+00]\n",
      "   [ 2.32042350e+01  2.74022573e+00 -2.61656018e+01]]\n",
      "\n",
      "  [[ 4.25648665e+01 -3.93149771e+01 -4.40825342e+01]\n",
      "   [-1.46261129e+01  1.52782070e+01  2.37119156e+01]\n",
      "   [ 2.04478549e+00  1.47055461e+01 -4.88407972e+01]\n",
      "   [-6.89580998e+01  2.24399900e+01 -5.41322535e+00]\n",
      "   [ 1.79219613e+01 -1.26949812e+01 -4.96126557e+01]]]]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "ex3: Conv2d module does not pass gradient check",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[201], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Test Cell: do not edit or delete!\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m gradient_check(conv, x, debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), (\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mex3: Conv2d module does not pass gradient check\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m )\n",
      "\u001b[1;31mAssertionError\u001b[0m: ex3: Conv2d module does not pass gradient check"
     ]
    }
   ],
   "source": [
    "# Test Cell: do not edit or delete!\n",
    "assert gradient_check(conv, x, debug=True), (\n",
    "    \"ex3: Conv2d module does not pass gradient check\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions\n",
    "\n",
    "Although any activation function can be used in combination with convolutional neural networks, a very popular choice is the so-called *Rectified Linear Unit* (*ReLU*). The ReLU function maps all negative inputs to zero and all positive inputs to itself. Mathematically, this looks like\n",
    "\n",
    "$$\\mathrm{ReLU}(x) = \\begin{cases} 0 & x \\leq 0 \\\\ x & x > 0 \\end{cases}.$$\n",
    "\n",
    "An alternative activation function that is based on the ReLU, is the *Exponential Linear Unit* (*ELU*). Unlike the ReLU non-linearity, the ELU is able to keep the mean of the activations close to zero. It can be defined as follows:\n",
    "\n",
    "$$\\mathrm{ELU}(x \\mathbin{;} \\alpha) = \\begin{cases} \\alpha (e^x - 1) & x \\leq 0 \\\\ x & x > 0 \\end{cases}.$$\n",
    "\n",
    "The parameter $\\alpha$ in this non-linearity allows to specify the minimal negative value of the activations. Note that this $\\alpha$ is a hyper-parameter that must be fixed before training, and is thus not learned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Some Linear Units (3 Points)\n",
    "\n",
    "A deep learning framework would not be complete without the ReLU and ELU activation functions. Time to add them!\n",
    "\n",
    " > Implement the `ReLU` and `ELU` activation function modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d60dcdbe9fb4d2444a024b2fe7af91ab",
     "grade": false,
     "grade_id": "cell-2bc64dc13483ab48",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ReLU(Module):\n",
    "    \"\"\" NNumpy implementation of the Rectified Linear Unit. \"\"\"\n",
    "        \n",
    "    def compute_outputs(self, s):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        s : (N, K) ndarray\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        a : (N, K) ndarray\n",
    "        cache : ndarray or iterable of ndarrays\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        a = np.maximum(0, s)\n",
    "        return a, s\n",
    "\n",
    "    \n",
    "    def compute_grads(self, grads, cache):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        grads : (N, K) ndarray\n",
    "        cache : ndarray or iterable of ndarrays\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ds : (N, K) ndarrays\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        return grads * (cache > 0)\n",
    "        \n",
    "\n",
    "class ELU(Module):\n",
    "    \"\"\" NNumpy implementation of the Exponential Linear Unit. \"\"\"\n",
    "    \n",
    "    def __init__(self, alpha=1.):\n",
    "        super().__init__()\n",
    "        if alpha < 0:\n",
    "            raise ValueError(\"negative values for alpha are not allowed\")\n",
    "        \n",
    "        self.alpha = alpha\n",
    "        \n",
    "        \n",
    "    def compute_outputs(self, s):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        s : (N, K) ndarray\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        a : (N, K) ndarray\n",
    "        cache : ndarray or iterable of ndarrays\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        a = np.where(s > 0, s, self.alpha * (np.exp(s) - 1))\n",
    "        return a, s\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    def compute_grads(self, grads, cache):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        grads : (N, K) ndarray\n",
    "        cache : ndarray or iterable of ndarrays\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ds : (N, K) ndarrays\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        return grads * np.where(cache > 0, 1, self.alpha * np.exp(cache))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a3a01c64bc34b0d8965fb558ff09b043",
     "grade": true,
     "grade_id": "cell-90a715ea66b6f60d",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!\n",
    "s = np.linspace(-3, 3, 35).reshape(7, 5)\n",
    "phi = ReLU()\n",
    "a, cache = phi.compute_outputs(s)\n",
    "assert isinstance(a, np.ndarray), (\n",
    "    \"ex4: output of ReLU.compute_outputs is not a numpy array\"\n",
    ")\n",
    "assert a.shape == s.shape, (\n",
    "    \"ex4: output of ReLU.compute_outputs has incorrect shape\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1dc21597221e5bfd1dc3eafbd2f21737",
     "grade": true,
     "grade_id": "cell-ad8556b201315749",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!\n",
    "g = phi.compute_grads(np.ones_like(s), cache)\n",
    "assert isinstance(g, np.ndarray), (\n",
    "    \"ex4: output of ReLU.compute_grads is not a numpy array\"\n",
    ")\n",
    "assert g.shape == s.shape, (\n",
    "    \"ex4: output of ReLU.compute_grads has incorrect shape\"\n",
    ")\n",
    "assert gradient_check(phi, x, debug=True), (\n",
    "    \"ex4: ReLU module does not pass gradient check\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b29d808fd34656d84937480acad16911",
     "grade": true,
     "grade_id": "cell-6f081fec120b8661",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!\n",
    "s = np.linspace(-3, 3, 35).reshape(7, 5)\n",
    "phi = ELU()\n",
    "a, cache = phi.compute_outputs(s)\n",
    "assert isinstance(a, np.ndarray), (\n",
    "    \"ex4: output of ELU.compute_outputs is not a numpy array\"\n",
    ")\n",
    "assert a.shape == s.shape, (\n",
    "    \"ex4: output of ELU.compute_outputs has incorrect shape\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "74919cff779879f201aa0666fed819ef",
     "grade": true,
     "grade_id": "cell-03c96045eb154ef0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!\n",
    "g = phi.compute_grads(np.ones_like(s), cache)\n",
    "assert isinstance(g, np.ndarray), (\n",
    "    \"ex4: output of ELU.compute_grads is not a numpy array\"\n",
    ")\n",
    "assert g.shape == s.shape, (\n",
    "    \"ex4: output of ELU.compute_grads has incorrect shape\"\n",
    ")\n",
    "assert gradient_check(phi, x, debug=True), (\n",
    "    \"ex4: ELU module does not pass gradient check\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Reduction\n",
    "\n",
    "The *weight sharing* in convolutional neural networks can drastically reduce the memory requirements for the weights. This effectively allows the input data to become larger, but since we need to store parts of the forward pass for back-propagation, the gains are rather limited. Of course, standard convolutions reduce the spatial dimensions, but this linear reduction is often too slow to counter the increased memory requirements due to network depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Pooling\n",
    "\n",
    "In order to make working with big images feasible, we need techniques to reduce the spatial dimensions more strongly. This is where *pooling* layers prove very useful. A pooling layer reduces the spatial dimensions by combining a window of pixels to a single pixel. By sticking a pooling layer after every convolutional layer, the spatial dimensions are reduced exponentially, rather than linearly. This allows convolutional neural networks to process big chunks of data.\n",
    "\n",
    "There are different ways to summarise multiple pixels into a single pixel. Two very common pooling techniques are\n",
    "\n",
    " 1. **Average pooling** replaces the pixels by the mean intensity value in the window. \n",
    " 2. **Max pooling** replaces the pixels by the maximum intensity in the window.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Strides\n",
    "\n",
    "In modern convolutional neural networks, *strided* or *dilated* convolutions (see visualisations below) are often preferred over pooling. With strided convolutions, the windows are shifted The main advantage of strided or dilated convolutions over pooling is that they can be learnt. This means that instead of relying on a fixed pooling technique, it is possible to effectively learn how the pixels in the window are to be summarised. Also note that average pooling can indeed be represented as a strided convolution with weights $\\frac{1}{\\text{window size}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center\">\n",
    "  <figure style=\"display: inline-block; width: 49%;\">\n",
    "    <img style=\"padding: 46px 50px\" src=\"https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/no_padding_strides.gif\" />\n",
    "    <figcaption style=\"width: 100%;\"> Strided convolution </figcaption>\n",
    "  </figure>\n",
    "  <figure style=\"display: inline-block; width: 49%;\">\n",
    "    <img src=\"https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/dilation.gif\" />\n",
    "    <figcaption style=\"width: 100%; text-align: center;\"> Dilated convolution </figcaption>\n",
    "  </figure>\n",
    "</div>\n",
    "\n",
    "*visualisations taken from the [github repo](https://github.com/vdumoulin/conv_arithmetic) that comes with [this guide](https://arxiv.org/abs/1603.07285)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Pooling (5 Points)\n",
    "\n",
    "Since the `sig2col` function provides an array with the window elements in each column, it can also be used to implement pooling layers, when used correctly.\n",
    "\n",
    " > Implement the `MaxPool2d` module. You can use the `sig2col` function with its `stride` argument. You might also find the functions `np.take_along_axis` and `np.put_along_axis` useful.\n",
    " \n",
    "**Hint:** You can apply `sig2col` on `np.arange(x.size).reshape(x.shape)` to obtain the indices of the input after the `sig2col` operation. This could be useful for implementing the back-propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e2dcaa67f35dee139c2544b1eef344f7",
     "grade": false,
     "grade_id": "cell-a61825c7b1912064",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MaxPool2d(Module):\n",
    "    \"\"\" Numpy DL implementation of a max-pooling layer. \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size):\n",
    "        super().__init__()\n",
    "        self.kernel_size = tuple(kernel_size)\n",
    "\n",
    "    def compute_outputs(self, x):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : (N, C, H, W) ndarray\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        a : (N, C, H', W') ndarray\n",
    "        cache : ndarray or tuple of ndarrays\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "        s = sig2col(x, self.kernel_size, stride=self.kernel_size) # shape is N, C, H', W', R1, R2\n",
    "        s_flat = s.reshape(*s.shape[:-2], -1) # shape is N, C, H', W', R1 * R2 (last two dimensions are flattened)\n",
    "        indices = s_flat.argmax(axis=-1, keepdims=True) # \n",
    "        cache = (np.array(x.shape), np.array(s_flat.shape), indices)\n",
    "        a = np.take_along_axis(s_flat, indices, -1)[..., 0] # uses the indices along the last axis. Note that [..., 0] is the same as [:,:,:,:,0]\n",
    "        return a, cache\n",
    "\n",
    "    def compute_grads(self, grads, cache):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        grads : (N, C, H', W') ndarray\n",
    "        cache : ndarray or tuple of ndarrays\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dx : (N, C, H, W) ndarray\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        x_shape, s_flat_shape, indices = cache\n",
    "        s_grad_flat = np.zeros(s_flat_shape)\n",
    "        dx = np.empty(x_shape) # has the same shape as x\n",
    "\n",
    "        np.put_along_axis(s_grad_flat, indices, grads[..., np.newaxis], axis=-1) # put the gradients of the previous layer at the indices of the max values in the array s_grad_flat\n",
    "\n",
    "        # now we need to bring this into the right shape such that we can put that into dx\n",
    "\n",
    "        x_idx = np.arange(dx.size).reshape(x_shape) # like in the hint\n",
    "        x_idx_s = sig2col(x_idx, self.kernel_size, stride=self.kernel_size) # like in the hint\n",
    "        print(x_idx_s)\n",
    "        print(x_idx_s.ravel())\n",
    "        print(dx.size)\n",
    "        print(s_grad_flat)\n",
    "        dx.flat[x_idx_s.flatten()] = s_grad_flat.flatten()\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f33dfc5591f1c2d14c56aaefc342f5c",
     "grade": true,
     "grade_id": "cell-719ebf2001083942",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!\n",
    "pooling = MaxPool2d((2, 3))\n",
    "x = rng.standard_normal(size=(1, 1, 16, 18))\n",
    "p, cache = pooling.compute_outputs(x)\n",
    "assert isinstance(p, np.ndarray), (\n",
    "    \"ex5: output of MaxPool2d.compute_outputs is not a numpy array\"\n",
    ")\n",
    "assert p.shape == x.shape[:2] + (8, 6), (\n",
    "    \"ex5: output of MaxPool2d.compute_outputs has incorrect shape\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f58b1850656456ae8a7b1662c2e065ff",
     "grade": true,
     "grade_id": "cell-8fe3422e86b80745",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10e4b115cc2a6f2feda38a2b207af249",
     "grade": true,
     "grade_id": "cell-d117d5535940aaa3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[[[  0   1   2]\n",
      "     [ 18  19  20]]\n",
      "\n",
      "    [[  3   4   5]\n",
      "     [ 21  22  23]]\n",
      "\n",
      "    [[  6   7   8]\n",
      "     [ 24  25  26]]\n",
      "\n",
      "    [[  9  10  11]\n",
      "     [ 27  28  29]]\n",
      "\n",
      "    [[ 12  13  14]\n",
      "     [ 30  31  32]]\n",
      "\n",
      "    [[ 15  16  17]\n",
      "     [ 33  34  35]]]\n",
      "\n",
      "\n",
      "   [[[ 36  37  38]\n",
      "     [ 54  55  56]]\n",
      "\n",
      "    [[ 39  40  41]\n",
      "     [ 57  58  59]]\n",
      "\n",
      "    [[ 42  43  44]\n",
      "     [ 60  61  62]]\n",
      "\n",
      "    [[ 45  46  47]\n",
      "     [ 63  64  65]]\n",
      "\n",
      "    [[ 48  49  50]\n",
      "     [ 66  67  68]]\n",
      "\n",
      "    [[ 51  52  53]\n",
      "     [ 69  70  71]]]\n",
      "\n",
      "\n",
      "   [[[ 72  73  74]\n",
      "     [ 90  91  92]]\n",
      "\n",
      "    [[ 75  76  77]\n",
      "     [ 93  94  95]]\n",
      "\n",
      "    [[ 78  79  80]\n",
      "     [ 96  97  98]]\n",
      "\n",
      "    [[ 81  82  83]\n",
      "     [ 99 100 101]]\n",
      "\n",
      "    [[ 84  85  86]\n",
      "     [102 103 104]]\n",
      "\n",
      "    [[ 87  88  89]\n",
      "     [105 106 107]]]\n",
      "\n",
      "\n",
      "   [[[108 109 110]\n",
      "     [126 127 128]]\n",
      "\n",
      "    [[111 112 113]\n",
      "     [129 130 131]]\n",
      "\n",
      "    [[114 115 116]\n",
      "     [132 133 134]]\n",
      "\n",
      "    [[117 118 119]\n",
      "     [135 136 137]]\n",
      "\n",
      "    [[120 121 122]\n",
      "     [138 139 140]]\n",
      "\n",
      "    [[123 124 125]\n",
      "     [141 142 143]]]\n",
      "\n",
      "\n",
      "   [[[144 145 146]\n",
      "     [162 163 164]]\n",
      "\n",
      "    [[147 148 149]\n",
      "     [165 166 167]]\n",
      "\n",
      "    [[150 151 152]\n",
      "     [168 169 170]]\n",
      "\n",
      "    [[153 154 155]\n",
      "     [171 172 173]]\n",
      "\n",
      "    [[156 157 158]\n",
      "     [174 175 176]]\n",
      "\n",
      "    [[159 160 161]\n",
      "     [177 178 179]]]\n",
      "\n",
      "\n",
      "   [[[180 181 182]\n",
      "     [198 199 200]]\n",
      "\n",
      "    [[183 184 185]\n",
      "     [201 202 203]]\n",
      "\n",
      "    [[186 187 188]\n",
      "     [204 205 206]]\n",
      "\n",
      "    [[189 190 191]\n",
      "     [207 208 209]]\n",
      "\n",
      "    [[192 193 194]\n",
      "     [210 211 212]]\n",
      "\n",
      "    [[195 196 197]\n",
      "     [213 214 215]]]\n",
      "\n",
      "\n",
      "   [[[216 217 218]\n",
      "     [234 235 236]]\n",
      "\n",
      "    [[219 220 221]\n",
      "     [237 238 239]]\n",
      "\n",
      "    [[222 223 224]\n",
      "     [240 241 242]]\n",
      "\n",
      "    [[225 226 227]\n",
      "     [243 244 245]]\n",
      "\n",
      "    [[228 229 230]\n",
      "     [246 247 248]]\n",
      "\n",
      "    [[231 232 233]\n",
      "     [249 250 251]]]\n",
      "\n",
      "\n",
      "   [[[252 253 254]\n",
      "     [270 271 272]]\n",
      "\n",
      "    [[255 256 257]\n",
      "     [273 274 275]]\n",
      "\n",
      "    [[258 259 260]\n",
      "     [276 277 278]]\n",
      "\n",
      "    [[261 262 263]\n",
      "     [279 280 281]]\n",
      "\n",
      "    [[264 265 266]\n",
      "     [282 283 284]]\n",
      "\n",
      "    [[267 268 269]\n",
      "     [285 286 287]]]]]]\n",
      "[  0   1   2  18  19  20   3   4   5  21  22  23   6   7   8  24  25  26\n",
      "   9  10  11  27  28  29  12  13  14  30  31  32  15  16  17  33  34  35\n",
      "  36  37  38  54  55  56  39  40  41  57  58  59  42  43  44  60  61  62\n",
      "  45  46  47  63  64  65  48  49  50  66  67  68  51  52  53  69  70  71\n",
      "  72  73  74  90  91  92  75  76  77  93  94  95  78  79  80  96  97  98\n",
      "  81  82  83  99 100 101  84  85  86 102 103 104  87  88  89 105 106 107\n",
      " 108 109 110 126 127 128 111 112 113 129 130 131 114 115 116 132 133 134\n",
      " 117 118 119 135 136 137 120 121 122 138 139 140 123 124 125 141 142 143\n",
      " 144 145 146 162 163 164 147 148 149 165 166 167 150 151 152 168 169 170\n",
      " 153 154 155 171 172 173 156 157 158 174 175 176 159 160 161 177 178 179\n",
      " 180 181 182 198 199 200 183 184 185 201 202 203 186 187 188 204 205 206\n",
      " 189 190 191 207 208 209 192 193 194 210 211 212 195 196 197 213 214 215\n",
      " 216 217 218 234 235 236 219 220 221 237 238 239 222 223 224 240 241 242\n",
      " 225 226 227 243 244 245 228 229 230 246 247 248 231 232 233 249 250 251\n",
      " 252 253 254 270 271 272 255 256 257 273 274 275 258 259 260 276 277 278\n",
      " 261 262 263 279 280 281 264 265 266 282 283 284 267 268 269 285 286 287]\n",
      "288\n",
      "[[[[[0. 0. 0. 0. 0. 1.]\n",
      "    [0. 1. 0. 0. 0. 0.]\n",
      "    [0. 1. 0. 0. 0. 0.]\n",
      "    [0. 0. 0. 1. 0. 0.]\n",
      "    [0. 1. 0. 0. 0. 0.]\n",
      "    [0. 0. 0. 0. 1. 0.]]\n",
      "\n",
      "   [[1. 0. 0. 0. 0. 0.]\n",
      "    [1. 0. 0. 0. 0. 0.]\n",
      "    [0. 0. 0. 1. 0. 0.]\n",
      "    [0. 0. 0. 0. 1. 0.]\n",
      "    [0. 0. 0. 0. 0. 1.]\n",
      "    [0. 0. 0. 0. 0. 1.]]\n",
      "\n",
      "   [[1. 0. 0. 0. 0. 0.]\n",
      "    [0. 1. 0. 0. 0. 0.]\n",
      "    [0. 0. 0. 1. 0. 0.]\n",
      "    [0. 1. 0. 0. 0. 0.]\n",
      "    [0. 0. 1. 0. 0. 0.]\n",
      "    [1. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "   [[1. 0. 0. 0. 0. 0.]\n",
      "    [0. 0. 0. 1. 0. 0.]\n",
      "    [0. 0. 0. 0. 1. 0.]\n",
      "    [0. 0. 0. 0. 1. 0.]\n",
      "    [0. 0. 0. 0. 0. 1.]\n",
      "    [0. 0. 1. 0. 0. 0.]]\n",
      "\n",
      "   [[0. 1. 0. 0. 0. 0.]\n",
      "    [0. 0. 1. 0. 0. 0.]\n",
      "    [0. 0. 0. 1. 0. 0.]\n",
      "    [0. 0. 1. 0. 0. 0.]\n",
      "    [1. 0. 0. 0. 0. 0.]\n",
      "    [0. 0. 1. 0. 0. 0.]]\n",
      "\n",
      "   [[0. 0. 1. 0. 0. 0.]\n",
      "    [1. 0. 0. 0. 0. 0.]\n",
      "    [0. 0. 0. 0. 0. 1.]\n",
      "    [1. 0. 0. 0. 0. 0.]\n",
      "    [0. 1. 0. 0. 0. 0.]\n",
      "    [0. 0. 1. 0. 0. 0.]]\n",
      "\n",
      "   [[0. 0. 0. 0. 0. 1.]\n",
      "    [0. 0. 0. 0. 1. 0.]\n",
      "    [1. 0. 0. 0. 0. 0.]\n",
      "    [0. 0. 0. 0. 1. 0.]\n",
      "    [0. 0. 1. 0. 0. 0.]\n",
      "    [0. 0. 0. 1. 0. 0.]]\n",
      "\n",
      "   [[0. 0. 0. 0. 0. 1.]\n",
      "    [0. 1. 0. 0. 0. 0.]\n",
      "    [0. 1. 0. 0. 0. 0.]\n",
      "    [0. 1. 0. 0. 0. 0.]\n",
      "    [0. 0. 0. 1. 0. 0.]\n",
      "    [0. 1. 0. 0. 0. 0.]]]]]\n"
     ]
    }
   ],
   "source": [
    "# Test Cell: do not edit or delete!\n",
    "g = pooling.compute_grads(np.ones_like(p), cache)\n",
    "assert isinstance(g, np.ndarray), (\n",
    "    \"ex5: output of MaxPool2d.compute_grads is not a numpy array\"\n",
    ")\n",
    "assert g.shape == x.shape, (\n",
    "    \"ex5: output of MaxPool2d.compute_grads has incorrect shape\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0b16c03c3cfd41b9e25fee2dafce2f03",
     "grade": true,
     "grade_id": "cell-1fb2fd9fe50164fc",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[[[  0   1   2]\n",
      "     [ 18  19  20]]\n",
      "\n",
      "    [[  3   4   5]\n",
      "     [ 21  22  23]]\n",
      "\n",
      "    [[  6   7   8]\n",
      "     [ 24  25  26]]\n",
      "\n",
      "    [[  9  10  11]\n",
      "     [ 27  28  29]]\n",
      "\n",
      "    [[ 12  13  14]\n",
      "     [ 30  31  32]]\n",
      "\n",
      "    [[ 15  16  17]\n",
      "     [ 33  34  35]]]\n",
      "\n",
      "\n",
      "   [[[ 36  37  38]\n",
      "     [ 54  55  56]]\n",
      "\n",
      "    [[ 39  40  41]\n",
      "     [ 57  58  59]]\n",
      "\n",
      "    [[ 42  43  44]\n",
      "     [ 60  61  62]]\n",
      "\n",
      "    [[ 45  46  47]\n",
      "     [ 63  64  65]]\n",
      "\n",
      "    [[ 48  49  50]\n",
      "     [ 66  67  68]]\n",
      "\n",
      "    [[ 51  52  53]\n",
      "     [ 69  70  71]]]\n",
      "\n",
      "\n",
      "   [[[ 72  73  74]\n",
      "     [ 90  91  92]]\n",
      "\n",
      "    [[ 75  76  77]\n",
      "     [ 93  94  95]]\n",
      "\n",
      "    [[ 78  79  80]\n",
      "     [ 96  97  98]]\n",
      "\n",
      "    [[ 81  82  83]\n",
      "     [ 99 100 101]]\n",
      "\n",
      "    [[ 84  85  86]\n",
      "     [102 103 104]]\n",
      "\n",
      "    [[ 87  88  89]\n",
      "     [105 106 107]]]\n",
      "\n",
      "\n",
      "   [[[108 109 110]\n",
      "     [126 127 128]]\n",
      "\n",
      "    [[111 112 113]\n",
      "     [129 130 131]]\n",
      "\n",
      "    [[114 115 116]\n",
      "     [132 133 134]]\n",
      "\n",
      "    [[117 118 119]\n",
      "     [135 136 137]]\n",
      "\n",
      "    [[120 121 122]\n",
      "     [138 139 140]]\n",
      "\n",
      "    [[123 124 125]\n",
      "     [141 142 143]]]\n",
      "\n",
      "\n",
      "   [[[144 145 146]\n",
      "     [162 163 164]]\n",
      "\n",
      "    [[147 148 149]\n",
      "     [165 166 167]]\n",
      "\n",
      "    [[150 151 152]\n",
      "     [168 169 170]]\n",
      "\n",
      "    [[153 154 155]\n",
      "     [171 172 173]]\n",
      "\n",
      "    [[156 157 158]\n",
      "     [174 175 176]]\n",
      "\n",
      "    [[159 160 161]\n",
      "     [177 178 179]]]\n",
      "\n",
      "\n",
      "   [[[180 181 182]\n",
      "     [198 199 200]]\n",
      "\n",
      "    [[183 184 185]\n",
      "     [201 202 203]]\n",
      "\n",
      "    [[186 187 188]\n",
      "     [204 205 206]]\n",
      "\n",
      "    [[189 190 191]\n",
      "     [207 208 209]]\n",
      "\n",
      "    [[192 193 194]\n",
      "     [210 211 212]]\n",
      "\n",
      "    [[195 196 197]\n",
      "     [213 214 215]]]\n",
      "\n",
      "\n",
      "   [[[216 217 218]\n",
      "     [234 235 236]]\n",
      "\n",
      "    [[219 220 221]\n",
      "     [237 238 239]]\n",
      "\n",
      "    [[222 223 224]\n",
      "     [240 241 242]]\n",
      "\n",
      "    [[225 226 227]\n",
      "     [243 244 245]]\n",
      "\n",
      "    [[228 229 230]\n",
      "     [246 247 248]]\n",
      "\n",
      "    [[231 232 233]\n",
      "     [249 250 251]]]\n",
      "\n",
      "\n",
      "   [[[252 253 254]\n",
      "     [270 271 272]]\n",
      "\n",
      "    [[255 256 257]\n",
      "     [273 274 275]]\n",
      "\n",
      "    [[258 259 260]\n",
      "     [276 277 278]]\n",
      "\n",
      "    [[261 262 263]\n",
      "     [279 280 281]]\n",
      "\n",
      "    [[264 265 266]\n",
      "     [282 283 284]]\n",
      "\n",
      "    [[267 268 269]\n",
      "     [285 286 287]]]]]]\n",
      "[  0   1   2  18  19  20   3   4   5  21  22  23   6   7   8  24  25  26\n",
      "   9  10  11  27  28  29  12  13  14  30  31  32  15  16  17  33  34  35\n",
      "  36  37  38  54  55  56  39  40  41  57  58  59  42  43  44  60  61  62\n",
      "  45  46  47  63  64  65  48  49  50  66  67  68  51  52  53  69  70  71\n",
      "  72  73  74  90  91  92  75  76  77  93  94  95  78  79  80  96  97  98\n",
      "  81  82  83  99 100 101  84  85  86 102 103 104  87  88  89 105 106 107\n",
      " 108 109 110 126 127 128 111 112 113 129 130 131 114 115 116 132 133 134\n",
      " 117 118 119 135 136 137 120 121 122 138 139 140 123 124 125 141 142 143\n",
      " 144 145 146 162 163 164 147 148 149 165 166 167 150 151 152 168 169 170\n",
      " 153 154 155 171 172 173 156 157 158 174 175 176 159 160 161 177 178 179\n",
      " 180 181 182 198 199 200 183 184 185 201 202 203 186 187 188 204 205 206\n",
      " 189 190 191 207 208 209 192 193 194 210 211 212 195 196 197 213 214 215\n",
      " 216 217 218 234 235 236 219 220 221 237 238 239 222 223 224 240 241 242\n",
      " 225 226 227 243 244 245 228 229 230 246 247 248 231 232 233 249 250 251\n",
      " 252 253 254 270 271 272 255 256 257 273 274 275 258 259 260 276 277 278\n",
      " 261 262 263 279 280 281 264 265 266 282 283 284 267 268 269 285 286 287]\n",
      "288\n",
      "[[[[[ 0.          0.          0.          0.          0.\n",
      "      0.84114508]\n",
      "    [ 0.          0.77053054  0.          0.          0.\n",
      "      0.        ]\n",
      "    [ 0.          1.08835498  0.          0.          0.\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.         -1.21885706  0.\n",
      "      0.        ]\n",
      "    [ 0.         -0.21013356  0.          0.          0.\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.          0.          0.40321339\n",
      "      0.        ]]\n",
      "\n",
      "   [[-2.62853679  0.          0.          0.          0.\n",
      "      0.        ]\n",
      "    [ 0.84631015  0.          0.          0.          0.\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.          0.73498927  0.\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.          0.         -0.67165704\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.          0.          0.\n",
      "     -0.12812768]\n",
      "    [ 0.          0.          0.          0.          0.\n",
      "     -0.33018049]]\n",
      "\n",
      "   [[ 0.42094445  0.          0.          0.          0.\n",
      "      0.        ]\n",
      "    [ 0.          1.30697197  0.          0.          0.\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.         -0.69829769  0.\n",
      "      0.        ]\n",
      "    [ 0.          1.58950559  0.          0.          0.\n",
      "      0.        ]\n",
      "    [ 0.          0.          1.4426604   0.          0.\n",
      "      0.        ]\n",
      "    [-0.39083155  0.          0.          0.          0.\n",
      "      0.        ]]\n",
      "\n",
      "   [[-2.89230153  0.          0.          0.          0.\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.          0.19260308  0.\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.          0.          1.00391748\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.          0.          0.11968606\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.          0.          0.\n",
      "      1.85622306]\n",
      "    [ 0.          0.         -0.21991261  0.          0.\n",
      "      0.        ]]\n",
      "\n",
      "   [[ 0.         -0.22502846  0.          0.          0.\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.43707693  0.          0.\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.         -0.4820469   0.\n",
      "      0.        ]\n",
      "    [ 0.          0.          1.1623374   0.          0.\n",
      "      0.        ]\n",
      "    [ 0.36811062  0.          0.          0.          0.\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.69196918  0.          0.\n",
      "      0.        ]]\n",
      "\n",
      "   [[ 0.          0.          1.28739639  0.          0.\n",
      "      0.        ]\n",
      "    [-0.56825941  0.          0.          0.          0.\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.          0.          0.\n",
      "      1.02416769]\n",
      "    [ 1.24556477  0.          0.          0.          0.\n",
      "      0.        ]\n",
      "    [ 0.          0.04277076  0.          0.          0.\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.06329566  0.          0.\n",
      "      0.        ]]\n",
      "\n",
      "   [[ 0.          0.          0.          0.          0.\n",
      "     -2.12807727]\n",
      "    [ 0.          0.          0.          0.         -1.07146292\n",
      "      0.        ]\n",
      "    [ 0.63591258  0.          0.          0.          0.\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.          0.          1.97305853\n",
      "      0.        ]\n",
      "    [ 0.          0.         -1.52313646  0.          0.\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.          0.04260246  0.\n",
      "      0.        ]]\n",
      "\n",
      "   [[ 0.          0.          0.          0.          0.\n",
      "     -0.81250149]\n",
      "    [ 0.         -0.46270295  0.          0.          0.\n",
      "      0.        ]\n",
      "    [ 0.          0.899986    0.          0.          0.\n",
      "      0.        ]\n",
      "    [ 0.         -0.74767693  0.          0.          0.\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.          0.55983257  0.\n",
      "      0.        ]\n",
      "    [ 0.         -0.53328936  0.          0.          0.\n",
      "      0.        ]]]]]\n"
     ]
    }
   ],
   "source": [
    "# Test Cell: do not edit or delete!\n",
    "assert gradient_check(pooling, x, debug=True), (\n",
    "    \"ex5: MaxPool2d module does not pass gradient check\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[[[  0   1   2]\n",
      "     [ 18  19  20]]\n",
      "\n",
      "    [[  3   4   5]\n",
      "     [ 21  22  23]]\n",
      "\n",
      "    [[  6   7   8]\n",
      "     [ 24  25  26]]\n",
      "\n",
      "    [[  9  10  11]\n",
      "     [ 27  28  29]]\n",
      "\n",
      "    [[ 12  13  14]\n",
      "     [ 30  31  32]]\n",
      "\n",
      "    [[ 15  16  17]\n",
      "     [ 33  34  35]]]\n",
      "\n",
      "\n",
      "   [[[ 36  37  38]\n",
      "     [ 54  55  56]]\n",
      "\n",
      "    [[ 39  40  41]\n",
      "     [ 57  58  59]]\n",
      "\n",
      "    [[ 42  43  44]\n",
      "     [ 60  61  62]]\n",
      "\n",
      "    [[ 45  46  47]\n",
      "     [ 63  64  65]]\n",
      "\n",
      "    [[ 48  49  50]\n",
      "     [ 66  67  68]]\n",
      "\n",
      "    [[ 51  52  53]\n",
      "     [ 69  70  71]]]\n",
      "\n",
      "\n",
      "   [[[ 72  73  74]\n",
      "     [ 90  91  92]]\n",
      "\n",
      "    [[ 75  76  77]\n",
      "     [ 93  94  95]]\n",
      "\n",
      "    [[ 78  79  80]\n",
      "     [ 96  97  98]]\n",
      "\n",
      "    [[ 81  82  83]\n",
      "     [ 99 100 101]]\n",
      "\n",
      "    [[ 84  85  86]\n",
      "     [102 103 104]]\n",
      "\n",
      "    [[ 87  88  89]\n",
      "     [105 106 107]]]\n",
      "\n",
      "\n",
      "   [[[108 109 110]\n",
      "     [126 127 128]]\n",
      "\n",
      "    [[111 112 113]\n",
      "     [129 130 131]]\n",
      "\n",
      "    [[114 115 116]\n",
      "     [132 133 134]]\n",
      "\n",
      "    [[117 118 119]\n",
      "     [135 136 137]]\n",
      "\n",
      "    [[120 121 122]\n",
      "     [138 139 140]]\n",
      "\n",
      "    [[123 124 125]\n",
      "     [141 142 143]]]\n",
      "\n",
      "\n",
      "   [[[144 145 146]\n",
      "     [162 163 164]]\n",
      "\n",
      "    [[147 148 149]\n",
      "     [165 166 167]]\n",
      "\n",
      "    [[150 151 152]\n",
      "     [168 169 170]]\n",
      "\n",
      "    [[153 154 155]\n",
      "     [171 172 173]]\n",
      "\n",
      "    [[156 157 158]\n",
      "     [174 175 176]]\n",
      "\n",
      "    [[159 160 161]\n",
      "     [177 178 179]]]\n",
      "\n",
      "\n",
      "   [[[180 181 182]\n",
      "     [198 199 200]]\n",
      "\n",
      "    [[183 184 185]\n",
      "     [201 202 203]]\n",
      "\n",
      "    [[186 187 188]\n",
      "     [204 205 206]]\n",
      "\n",
      "    [[189 190 191]\n",
      "     [207 208 209]]\n",
      "\n",
      "    [[192 193 194]\n",
      "     [210 211 212]]\n",
      "\n",
      "    [[195 196 197]\n",
      "     [213 214 215]]]\n",
      "\n",
      "\n",
      "   [[[216 217 218]\n",
      "     [234 235 236]]\n",
      "\n",
      "    [[219 220 221]\n",
      "     [237 238 239]]\n",
      "\n",
      "    [[222 223 224]\n",
      "     [240 241 242]]\n",
      "\n",
      "    [[225 226 227]\n",
      "     [243 244 245]]\n",
      "\n",
      "    [[228 229 230]\n",
      "     [246 247 248]]\n",
      "\n",
      "    [[231 232 233]\n",
      "     [249 250 251]]]\n",
      "\n",
      "\n",
      "   [[[252 253 254]\n",
      "     [270 271 272]]\n",
      "\n",
      "    [[255 256 257]\n",
      "     [273 274 275]]\n",
      "\n",
      "    [[258 259 260]\n",
      "     [276 277 278]]\n",
      "\n",
      "    [[261 262 263]\n",
      "     [279 280 281]]\n",
      "\n",
      "    [[264 265 266]\n",
      "     [282 283 284]]\n",
      "\n",
      "    [[267 268 269]\n",
      "     [285 286 287]]]]]]\n",
      "[  0   1   2  18  19  20   3   4   5  21  22  23   6   7   8  24  25  26\n",
      "   9  10  11  27  28  29  12  13  14  30  31  32  15  16  17  33  34  35\n",
      "  36  37  38  54  55  56  39  40  41  57  58  59  42  43  44  60  61  62\n",
      "  45  46  47  63  64  65  48  49  50  66  67  68  51  52  53  69  70  71\n",
      "  72  73  74  90  91  92  75  76  77  93  94  95  78  79  80  96  97  98\n",
      "  81  82  83  99 100 101  84  85  86 102 103 104  87  88  89 105 106 107\n",
      " 108 109 110 126 127 128 111 112 113 129 130 131 114 115 116 132 133 134\n",
      " 117 118 119 135 136 137 120 121 122 138 139 140 123 124 125 141 142 143\n",
      " 144 145 146 162 163 164 147 148 149 165 166 167 150 151 152 168 169 170\n",
      " 153 154 155 171 172 173 156 157 158 174 175 176 159 160 161 177 178 179\n",
      " 180 181 182 198 199 200 183 184 185 201 202 203 186 187 188 204 205 206\n",
      " 189 190 191 207 208 209 192 193 194 210 211 212 195 196 197 213 214 215\n",
      " 216 217 218 234 235 236 219 220 221 237 238 239 222 223 224 240 241 242\n",
      " 225 226 227 243 244 245 228 229 230 246 247 248 231 232 233 249 250 251\n",
      " 252 253 254 270 271 272 255 256 257 273 274 275 258 259 260 276 277 278\n",
      " 261 262 263 279 280 281 264 265 266 282 283 284 267 268 269 285 286 287]\n",
      "288\n",
      "[[[[[ 0.23643403  0.          0.          0.          0.\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.          0.         -0.23226099\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.          0.          0.\n",
      "      1.126714  ]\n",
      "    [ 0.          0.78398485  0.          0.          0.\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.         -1.66825152  0.\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.         -1.0858331   0.\n",
      "      0.        ]]\n",
      "\n",
      "   [[ 0.          0.          0.         -2.86126166  0.\n",
      "      0.        ]\n",
      "    [-0.46826347  0.          0.          0.          0.\n",
      "      0.        ]\n",
      "    [ 0.          0.         -0.67290454  0.          0.\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.          0.65510513  0.\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.          0.         -0.46088064\n",
      "      0.        ]\n",
      "    [-0.83783765  0.          0.          0.          0.\n",
      "      0.        ]]\n",
      "\n",
      "   [[ 0.          0.          0.          0.          0.75798041\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.          0.          0.2686233\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.          0.          0.\n",
      "      2.29546084]\n",
      "    [ 0.84063239  0.          0.          0.          0.\n",
      "      0.        ]\n",
      "    [ 0.          0.         -0.48595344  0.          0.\n",
      "      0.        ]\n",
      "    [ 1.62795248  0.          0.          0.          0.\n",
      "      0.        ]]\n",
      "\n",
      "   [[ 1.51342912  0.          0.          0.          0.\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.         -0.47211675  0.\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.          0.32716122  0.\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.         -1.22168848  0.\n",
      "      0.        ]\n",
      "    [ 0.          0.36303853  0.          0.          0.\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.          0.         -0.84909433\n",
      "      0.        ]]\n",
      "\n",
      "   [[ 0.          0.          0.69080094  0.          0.\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.         -1.00579716  0.\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.          0.          0.\n",
      "      0.7098935 ]\n",
      "    [ 0.          0.          0.          0.          1.62550997\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.         -0.95895896  0.\n",
      "      0.        ]\n",
      "    [ 0.          0.27875738  0.          0.          0.\n",
      "      0.        ]]\n",
      "\n",
      "   [[ 0.          0.          0.74427291  0.          0.\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.          0.         -1.23411092\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.          0.          0.\n",
      "      1.20671665]\n",
      "    [ 1.2330651   0.          0.          0.          0.\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.          0.2836725   0.\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.          0.          0.04099187\n",
      "      0.        ]]\n",
      "\n",
      "   [[ 0.          0.          0.          0.         -0.20790834\n",
      "      0.        ]\n",
      "    [ 0.          1.08107085  0.          0.          0.\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.21986249  0.          0.\n",
      "      0.        ]\n",
      "    [ 0.          0.75758961  0.          0.          0.\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.          0.          0.\n",
      "      1.39965978]\n",
      "    [ 0.          0.          0.12045132  0.          0.\n",
      "      0.        ]]\n",
      "\n",
      "   [[ 0.11784517  0.          0.          0.          0.\n",
      "      0.        ]\n",
      "    [ 0.         -1.2797629   0.          0.          0.\n",
      "      0.        ]\n",
      "    [-0.67859946  0.          0.          0.          0.\n",
      "      0.        ]\n",
      "    [ 0.         -0.2009858   0.          0.          0.\n",
      "      0.        ]\n",
      "    [ 0.          0.          0.          0.          0.\n",
      "     -1.18295425]\n",
      "    [ 0.          0.          0.         -1.30512615  0.\n",
      "      0.        ]]]]]\n",
      "gradient check for MaxPool2D: passed\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "pooling = MaxPool2d((2, 3))\n",
    "pool_check = gradient_check(pooling, rng.standard_normal(size=(1, 1, 16, 18)), debug=True)\n",
    "print(\"gradient check for MaxPool2D:\", \"passed\" if pool_check else \"failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
